{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_data import load_sentences, trim_and_pad_audio_data\n",
    "import utils.layers as layers\n",
    "from models.emotion_recognition import ClassifyEmotion\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
    "\n",
    "data, label, metadata = load_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_labels = LabelEncoder().fit_transform(label)\n",
    "int_labels = int_labels.reshape(len(int_labels), 1)\n",
    "labels = OneHotEncoder().fit_transform(int_labels).toarray() \n",
    "\n",
    "# Split into train and test\n",
    "train_x, val_x, train_y, val_y = train_test_split(data, labels,\n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 47 (128, 2000, 26) (128, 6)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 \n",
    "batched_data = [train_x[i:i+batch_size] for i in range(0, len(train_x), batch_size)]\n",
    "batched_labels = [train_y[i:i+batch_size] for i in range(0, len(train_y), batch_size)]\n",
    "\n",
    "print(len(batched_data),len(batched_labels),batched_data[0].shape, batched_labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 128)\n",
      "(?, 128)\n",
      "(?, 512)\n",
      "(?, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ea6fa896acfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             }\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "num_features = 26 \n",
    "num_classes = 6\n",
    "learning_rate = 1e-4\n",
    "epochs = 5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.name_scope('inputs'):\n",
    "    x = tf.placeholder(shape=(None, None, num_features), dtype=tf.float32)\n",
    "    y = tf.placeholder(shape=(None, num_classes), dtype=tf.float32)\n",
    "    \n",
    "concat_lstm1 = layers.blstm(0, 64, x, return_all=True)\n",
    "# with tf.variable_scope('lstm1'):\n",
    "#     cell_fw = tf.nn.rnn_cell.LSTMCell(64, state_is_tuple=True)\n",
    "#     cell_bw = tf.nn.rnn_cell.LSTMCell(64, state_is_tuple=True)\n",
    "#     outputs_1, states_1 = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, inputs=x, dtype=tf.float32)\n",
    "#     concat_lstm1 = tf.concat(outputs_1, 2)\n",
    "#     print(concat_lstm1.shape)\n",
    "\n",
    "concat_lstm2 = layers.blstm(1, 64, concat_lstm1, return_all=False)\n",
    "# with tf.variable_scope('lstm2'):\n",
    "#     cell_fw2 = tf.nn.rnn_cell.LSTMCell(64, state_is_tuple=True)\n",
    "#     cell_bw2 = tf.nn.rnn_cell.LSTMCell(64, state_is_tuple=True)\n",
    "#     outputs_2, states_2 = tf.nn.bidirectional_dynamic_rnn(cell_fw2, cell_bw2, inputs=concat_lstm1, dtype=tf.float32)\n",
    "#     concat_lstm2 = tf.concat(outputs_2, 2)\n",
    "#     concat_lstm2 = tf.transpose(concat_lstm2, [1,0,2])[-1]\n",
    "#     print(concat_lstm2.shape)\n",
    "\n",
    "with tf.name_scope('dense'):\n",
    "    dense_0 = tf.layers.dense(concat_lstm2, 512, activation=tf.nn.tanh)\n",
    "    print(dense_0.shape)\n",
    "    logits= tf.layers.dense(dense_0, num_classes)\n",
    "    print(logits.shape)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits))\n",
    "    \n",
    "step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        batch_losses = [] \n",
    "        for i, batch in enumerate(batched_data):\n",
    "            labels_batch = batched_labels[i]\n",
    "            feed_dict = {\n",
    "                x: batch,\n",
    "                y: labels_batch\n",
    "            }\n",
    "            _, err = sess.run([step, loss], feed_dict=feed_dict)\n",
    "            batch_losses.append(err)\n",
    "        if epoch % 1 == 0: \n",
    "            print(np.mean(batch_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to training data\n",
    "training_data_path = 'data/conversations_lenmax22_formersents2_with_former'\n",
    "\n",
    "# path to all_words\n",
    "all_words_path = 'data/all_words.txt'\n",
    "\n",
    "# training parameters \n",
    "CHECKPOINT = True\n",
    "train_model_path = 'model'\n",
    "train_model_name = 'model-55'\n",
    "start_epoch = 56\n",
    "start_batch = 0\n",
    "batch_size = 25\n",
    "\n",
    "# for RL training\n",
    "training_type = 'normal' # 'normal' for seq2seq training, 'pg' for policy gradient\n",
    "reversed_model_path = 'Adam_encode22_decode22_reversed-maxlen22_lr0.0001_batch25_wordthres6'\n",
    "reversed_model_name = 'model-63'\n",
    "\n",
    "# data reader shuffle index list\n",
    "load_list = False\n",
    "index_list_file = 'data/shuffle_index_list'\n",
    "cur_train_index = start_batch * batch_size\n",
    "\n",
    "# word count threshold\n",
    "WC_threshold = 20\n",
    "reversed_WC_threshold = 6\n",
    "\n",
    "# dialog simulation turns\n",
    "MAX_TURNS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cornell Movie-Dialogs Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/parse.sh\n",
    "\n",
    "# coding=utf-8\n",
    "\n",
    "from __future__ import print_function\n",
    "import pickle\n",
    "import codecs\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import config\n",
    "\n",
    "def preProBuildWordVocab(word_count_threshold=5, all_words_path=config.all_words_path):\n",
    "    # borrowed this function from NeuralTalk\n",
    "\n",
    "    if not os.path.exists(all_words_path):\n",
    "        parse_all_words(all_words_path)\n",
    "\n",
    "    corpus = open(all_words_path, 'r').read().split('\\n')[:-1]\n",
    "    captions = np.asarray(corpus, dtype=np.object)\n",
    "\n",
    "    captions = map(lambda x: x.replace('.', ''), captions)\n",
    "    captions = map(lambda x: x.replace(',', ''), captions)\n",
    "    captions = map(lambda x: x.replace('\"', ''), captions)\n",
    "    captions = map(lambda x: x.replace('\\n', ''), captions)\n",
    "    captions = map(lambda x: x.replace('?', ''), captions)\n",
    "    captions = map(lambda x: x.replace('!', ''), captions)\n",
    "    captions = map(lambda x: x.replace('\\\\', ''), captions)\n",
    "    captions = map(lambda x: x.replace('/', ''), captions)\n",
    "\n",
    "    print('preprocessing word counts and creating vocab based on word count threshold %d' % (word_count_threshold))\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in captions:\n",
    "        nsents += 1\n",
    "        for w in sent.lower().split(' '):\n",
    "           word_counts[w] = word_counts.get(w, 0) + 1\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print('filtered words from %d to %d' % (len(word_counts), len(vocab)))\n",
    "\n",
    "    ixtoword = {}\n",
    "    ixtoword[0] = '<pad>'\n",
    "    ixtoword[1] = '<bos>'\n",
    "    ixtoword[2] = '<eos>'\n",
    "    ixtoword[3] = '<unk>'\n",
    "\n",
    "    wordtoix = {}\n",
    "    wordtoix['<pad>'] = 0\n",
    "    wordtoix['<bos>'] = 1\n",
    "    wordtoix['<eos>'] = 2\n",
    "    wordtoix['<unk>'] = 3\n",
    "\n",
    "    for idx, w in enumerate(vocab):\n",
    "        wordtoix[w] = idx+4\n",
    "        ixtoword[idx+4] = w\n",
    "\n",
    "    word_counts['<pad>'] = nsents\n",
    "    word_counts['<bos>'] = nsents\n",
    "    word_counts['<eos>'] = nsents\n",
    "    word_counts['<unk>'] = nsents\n",
    "\n",
    "    bias_init_vector = np.array([1.0 * word_counts[ixtoword[i]] for i in ixtoword])\n",
    "    bias_init_vector /= np.sum(bias_init_vector) # normalize to frequencies\n",
    "    bias_init_vector = np.log(bias_init_vector)\n",
    "    bias_init_vector -= np.max(bias_init_vector) # shift to nice numeric range\n",
    "\n",
    "    return wordtoix, ixtoword, bias_init_vector\n",
    "\n",
    "def parse_all_words(all_words_path):\n",
    "    raw_movie_lines = open('data/movie_lines.txt', 'r', encoding='utf-8', errors='ignore').read().split('\\n')[:-1]\n",
    "\n",
    "    with codecs.open(all_words_path, \"w\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in raw_movie_lines:\n",
    "            line = line.split(' +++$+++ ')\n",
    "            utterance = line[-1]\n",
    "            f.write(utterance + '\\n')\n",
    "\n",
    "\"\"\" Extract only the vocabulary part of the data \"\"\"\n",
    "def refine(data):\n",
    "    words = re.findall(\"[a-zA-Z'-]+\", data)\n",
    "    words = [\"\".join(word.split(\"'\")) for word in words]\n",
    "    # words = [\"\".join(word.split(\"-\")) for word in words]\n",
    "    data = ' '.join(words)\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parse_all_words(config.all_words_path)\n",
    "\n",
    "    raw_movie_lines = open('data/movie_lines.txt', 'r', encoding='utf-8', errors='ignore').read().split('\\n')[:-1]\n",
    "    \n",
    "    utterance_dict = {}\n",
    "    with codecs.open('data/tokenized_all_words.txt', \"w\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in raw_movie_lines:\n",
    "            line = line.split(' +++$+++ ')\n",
    "            line_ID = line[0]\n",
    "            utterance = line[-1]\n",
    "            utterance_dict[line_ID] = utterance\n",
    "            utterance = \" \".join([refine(w) for w in utterance.lower().split()])\n",
    "            f.write(utterance + '\\n')\n",
    "    pickle.dump(utterance_dict, open('data/utterance_dict', 'wb'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/train.sh\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from data_reader import Data_Reader\n",
    "import data_parser\n",
    "import config\n",
    "\n",
    "from model import Seq2Seq_chatbot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "### Global Parameters ###\n",
    "checkpoint = config.CHECKPOINT\n",
    "model_path = config.train_model_path\n",
    "model_name = config.train_model_name\n",
    "start_epoch = config.start_epoch\n",
    "\n",
    "word_count_threshold = config.WC_threshold\n",
    "\n",
    "### Train Parameters ###\n",
    "dim_wordvec = 300\n",
    "dim_hidden = 1000\n",
    "\n",
    "n_encode_lstm_step = 22 + 22\n",
    "n_decode_lstm_step = 22\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):\n",
    "    if not hasattr(sequences, '__len__'):\n",
    "        raise ValueError('`sequences` must be iterable.')\n",
    "    lengths = []\n",
    "    for x in sequences:\n",
    "        if not hasattr(x, '__len__'):\n",
    "            raise ValueError('`sequences` must be a list of iterables. '\n",
    "                             'Found non-iterable: ' + str(x))\n",
    "        lengths.append(len(x))\n",
    "\n",
    "    num_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x\n",
    "\n",
    "def train():\n",
    "    wordtoix, ixtoword, bias_init_vector = data_parser.preProBuildWordVocab(word_count_threshold=word_count_threshold)\n",
    "    word_vector = KeyedVectors.load_word2vec_format('model/word_vector.bin', binary=True)\n",
    "\n",
    "    model = Seq2Seq_chatbot(\n",
    "            dim_wordvec=dim_wordvec,\n",
    "            n_words=len(wordtoix),\n",
    "            dim_hidden=dim_hidden,\n",
    "            batch_size=batch_size,\n",
    "            n_encode_lstm_step=n_encode_lstm_step,\n",
    "            n_decode_lstm_step=n_decode_lstm_step,\n",
    "            bias_init_vector=bias_init_vector,\n",
    "            lr=learning_rate)\n",
    "\n",
    "    train_op, tf_loss, word_vectors, tf_caption, tf_caption_mask, inter_value = model.build_model()\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "    if checkpoint:\n",
    "        print(\"Use Model {}.\".format(model_name))\n",
    "        saver.restore(sess, os.path.join(model_path, model_name))\n",
    "        print(\"Model {} restored.\".format(model_name))\n",
    "    else:\n",
    "        print(\"Restart training...\")\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "    dr = Data_Reader()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        n_batch = dr.get_batch_num(batch_size)\n",
    "        for batch in range(n_batch):\n",
    "            start_time = time.time()\n",
    "\n",
    "            batch_X, batch_Y = dr.generate_training_batch(batch_size)\n",
    "\n",
    "            for i in range(len(batch_X)):\n",
    "                batch_X[i] = [word_vector[w] if w in word_vector else np.zeros(dim_wordvec) for w in batch_X[i]]\n",
    "                # batch_X[i].insert(0, np.random.normal(size=(dim_wordvec,))) # insert random normal at the first step\n",
    "                if len(batch_X[i]) > n_encode_lstm_step:\n",
    "                    batch_X[i] = batch_X[i][:n_encode_lstm_step]\n",
    "                else:\n",
    "                    for _ in range(len(batch_X[i]), n_encode_lstm_step):\n",
    "                        batch_X[i].append(np.zeros(dim_wordvec))\n",
    "\n",
    "            current_feats = np.array(batch_X)\n",
    "\n",
    "            current_captions = batch_Y\n",
    "            current_captions = map(lambda x: '<bos> ' + x, current_captions)\n",
    "            current_captions = map(lambda x: x.replace('.', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace(',', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('\"', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('\\n', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('?', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('!', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('\\\\', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('/', ''), current_captions)\n",
    "\n",
    "            for idx, each_cap in enumerate(current_captions):\n",
    "                word = each_cap.lower().split(' ')\n",
    "                if len(word) < n_decode_lstm_step:\n",
    "                    current_captions[idx] = current_captions[idx] + ' <eos>'\n",
    "                else:\n",
    "                    new_word = ''\n",
    "                    for i in range(n_decode_lstm_step-1):\n",
    "                        new_word = new_word + word[i] + ' '\n",
    "                    current_captions[idx] = new_word + '<eos>'\n",
    "\n",
    "            current_caption_ind = []\n",
    "            for cap in current_captions:\n",
    "                current_word_ind = []\n",
    "                for word in cap.lower().split(' '):\n",
    "                    if word in wordtoix:\n",
    "                        current_word_ind.append(wordtoix[word])\n",
    "                    else:\n",
    "                        current_word_ind.append(wordtoix['<unk>'])\n",
    "                current_caption_ind.append(current_word_ind)\n",
    "\n",
    "            current_caption_matrix = pad_sequences(current_caption_ind, padding='post', maxlen=n_decode_lstm_step)\n",
    "            current_caption_matrix = np.hstack([current_caption_matrix, np.zeros([len(current_caption_matrix), 1])]).astype(int)\n",
    "            current_caption_masks = np.zeros((current_caption_matrix.shape[0], current_caption_matrix.shape[1]))\n",
    "            nonzeros = np.array(map(lambda x: (x != 0).sum() + 1, current_caption_matrix))\n",
    "\n",
    "            for ind, row in enumerate(current_caption_masks):\n",
    "                row[:nonzeros[ind]] = 1\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                _, loss_val = sess.run(\n",
    "                        [train_op, tf_loss],\n",
    "                        feed_dict={\n",
    "                            word_vectors: current_feats,\n",
    "                            tf_caption: current_caption_matrix,\n",
    "                            tf_caption_mask: current_caption_masks\n",
    "                        })\n",
    "                print(\"Epoch: {}, batch: {}, loss: {}, Elapsed time: {}\".format(epoch, batch, loss_val, time.time() - start_time))\n",
    "            else:\n",
    "                _ = sess.run(train_op,\n",
    "                             feed_dict={\n",
    "                                word_vectors: current_feats,\n",
    "                                tf_caption: current_caption_matrix,\n",
    "                                tf_caption_mask: current_caption_masks\n",
    "                            })\n",
    "\n",
    "\n",
    "        print(\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
    "        saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/test.sh <PATH TO MODEL> <INPUT FILE> <OUTPUT FILE>\n",
    "\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"python\")\n",
    "import data_parser\n",
    "import config\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from rl_model import PolicyGradient_chatbot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#=====================================================\n",
    "# Global Parameters\n",
    "#=====================================================\n",
    "default_model_path = './model/RL/model-56-3000'\n",
    "testing_data_path = 'sample_input.txt' if len(sys.argv) <= 2 else sys.argv[2]\n",
    "output_path = 'sample_output_RL.txt' if len(sys.argv) <= 3 else sys.argv[3]\n",
    "\n",
    "word_count_threshold = config.WC_threshold\n",
    "\n",
    "#=====================================================\n",
    "# Train Parameters\n",
    "#=====================================================\n",
    "dim_wordvec = 300\n",
    "dim_hidden = 1000\n",
    "\n",
    "n_encode_lstm_step = 22 + 1 # one random normal as the first timestep\n",
    "n_decode_lstm_step = 22\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "\"\"\" Extract only the vocabulary part of the data \"\"\"\n",
    "def refine(data):\n",
    "    words = re.findall(\"[a-zA-Z'-]+\", data)\n",
    "    words = [\"\".join(word.split(\"'\")) for word in words]\n",
    "    # words = [\"\".join(word.split(\"-\")) for word in words]\n",
    "    data = ' '.join(words)\n",
    "    return data\n",
    "\n",
    "def test(model_path=default_model_path):\n",
    "    testing_data = open(testing_data_path, 'r').read().split('\\n')\n",
    "\n",
    "    word_vector = KeyedVectors.load_word2vec_format('model/word_vector.bin', binary=True)\n",
    "\n",
    "    _, ixtoword, bias_init_vector = data_parser.preProBuildWordVocab(word_count_threshold=word_count_threshold)\n",
    "\n",
    "    model = PolicyGradient_chatbot(\n",
    "            dim_wordvec=dim_wordvec,\n",
    "            n_words=len(ixtoword),\n",
    "            dim_hidden=dim_hidden,\n",
    "            batch_size=batch_size,\n",
    "            n_encode_lstm_step=n_encode_lstm_step,\n",
    "            n_decode_lstm_step=n_decode_lstm_step,\n",
    "            bias_init_vector=bias_init_vector)\n",
    "\n",
    "    word_vectors, caption_tf, feats = model.build_generator()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    try:\n",
    "        print('\\n=== Use model', model_path, '===\\n')\n",
    "        saver.restore(sess, model_path)\n",
    "    except:\n",
    "        print('\\nUse default model\\n')\n",
    "        saver.restore(sess, default_model_path)\n",
    "\n",
    "    with open(output_path, 'w') as out:\n",
    "        generated_sentences = []\n",
    "        bleu_score_avg = [0., 0.]\n",
    "        for idx, question in enumerate(testing_data):\n",
    "            print('question =>', question)\n",
    "\n",
    "            question = [refine(w) for w in question.lower().split()]\n",
    "            question = [word_vector[w] if w in word_vector else np.zeros(dim_wordvec) for w in question]\n",
    "            question.insert(0, np.random.normal(size=(dim_wordvec,))) # insert random normal at the first step\n",
    "\n",
    "            if len(question) > n_encode_lstm_step:\n",
    "                question = question[:n_encode_lstm_step]\n",
    "            else:\n",
    "                for _ in range(len(question), n_encode_lstm_step):\n",
    "                    question.append(np.zeros(dim_wordvec))\n",
    "\n",
    "            question = np.array([question]) # 1x22x300\n",
    "    \n",
    "            generated_word_index, prob_logit = sess.run([caption_tf, feats['probs']], feed_dict={word_vectors: question})\n",
    "            generated_word_index = np.array(generated_word_index).reshape(batch_size, n_decode_lstm_step)[0]\n",
    "            prob_logit = np.array(prob_logit).reshape(batch_size, n_decode_lstm_step, -1)[0]\n",
    "            # print('generated_word_index.shape', generated_word_index.shape)\n",
    "            # print('prob_logit.shape', prob_logit.shape)\n",
    "\n",
    "            # remove <unk> to second high prob. word\n",
    "            # print('generated_word_index', generated_word_index)\n",
    "            for i in range(len(generated_word_index)):\n",
    "                if generated_word_index[i] == 3:\n",
    "                    sort_prob_logit = sorted(prob_logit[i])\n",
    "                    # print('max val', sort_prob_logit[-1])\n",
    "                    # print('second max val', sort_prob_logit[-2])\n",
    "                    maxindex = np.where(prob_logit[i] == sort_prob_logit[-1])[0][0]\n",
    "                    secmaxindex = np.where(prob_logit[i] == sort_prob_logit[-2])[0][0]\n",
    "                    # print('max ind', maxindex, ixtoword[maxindex])\n",
    "                    # print('second max ind', secmaxindex, ixtoword[secmaxindex])\n",
    "                    generated_word_index[i] = secmaxindex\n",
    "            # print('generated_word_index', generated_word_index)\n",
    "\n",
    "            generated_words = []\n",
    "            for ind in generated_word_index:\n",
    "                generated_words.append(ixtoword[ind])\n",
    "\n",
    "            # generate sentence\n",
    "            punctuation = np.argmax(np.array(generated_words) == '<eos>') + 1\n",
    "            generated_words = generated_words[:punctuation]\n",
    "            generated_sentence = ' '.join(generated_words)\n",
    "\n",
    "            # modify the output sentence \n",
    "            generated_sentence = generated_sentence.replace('<bos> ', '')\n",
    "            generated_sentence = generated_sentence.replace(' <eos>', '')\n",
    "            generated_sentence = generated_sentence.replace('--', '')\n",
    "            generated_sentence = generated_sentence.split('  ')\n",
    "            for i in range(len(generated_sentence)):\n",
    "                generated_sentence[i] = generated_sentence[i].strip()\n",
    "                if len(generated_sentence[i]) > 1:\n",
    "                    generated_sentence[i] = generated_sentence[i][0].upper() + generated_sentence[i][1:] + '.'\n",
    "                else:\n",
    "                    generated_sentence[i] = generated_sentence[i].upper()\n",
    "            generated_sentence = ' '.join(generated_sentence)\n",
    "            generated_sentence = generated_sentence.replace(' i ', ' I ')\n",
    "            generated_sentence = generated_sentence.replace(\"i'm\", \"I'm\")\n",
    "            generated_sentence = generated_sentence.replace(\"i'd\", \"I'd\")\n",
    "            generated_sentence = generated_sentence.replace(\"i'll\", \"I'll\")\n",
    "            generated_sentence = generated_sentence.replace(\"i'v\", \"I'v\")\n",
    "            generated_sentence = generated_sentence.replace(\" - \", \"\")\n",
    "\n",
    "            print('generated_sentence =>', generated_sentence)\n",
    "            out.write(generated_sentence + '\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) > 1:\n",
    "        test(model_path=sys.argv[1])\n",
    "    else:\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/simulate.sh <PATH TO MODEL> <SIMULATE TYPE> <INPUT FILE> <OUTPUT FILE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you need to change the training_type parameter in python/config.py\n",
    "\n",
    "'normal' for seq2seq training, 'pg' for policy gradient\n",
    "\n",
    "you need to first train with 'normal' for some epochs till stable (at least 30 epoches is highly recommended)\n",
    "\n",
    "then change the method to 'pg' to optimize the reward function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/train_RL.sh\n",
    "\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "sys.path.append(\"python\")\n",
    "from model import Seq2Seq_chatbot\n",
    "from data_reader import Data_Reader\n",
    "import data_parser\n",
    "import config\n",
    "import re\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from rl_model import PolicyGradient_chatbot\n",
    "from scipy import spatial\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "### Global Parameters ###\n",
    "checkpoint = config.CHECKPOINT\n",
    "model_path = config.train_model_path\n",
    "model_name = config.train_model_name\n",
    "start_epoch = config.start_epoch\n",
    "start_batch = config.start_batch\n",
    "\n",
    "# reversed model\n",
    "reversed_model_path = config.reversed_model_path\n",
    "reversed_model_name = config.reversed_model_name\n",
    "\n",
    "word_count_threshold = config.WC_threshold\n",
    "r_word_count_threshold = config.reversed_WC_threshold\n",
    "\n",
    "# dialog simulation turns\n",
    "max_turns = config.MAX_TURNS\n",
    "\n",
    "dull_set = [\"I don't know what you're talking about.\", \"I don't know.\", \"You don't know.\", \"You know what I mean.\", \"I know what you mean.\", \"You know what I'm saying.\", \"You don't know anything.\"]\n",
    "\n",
    "### Train Parameters ###\n",
    "training_type = config.training_type    # 'normal' for seq2seq training, 'pg' for policy gradient\n",
    "\n",
    "dim_wordvec = 300\n",
    "dim_hidden = 1000\n",
    "\n",
    "n_encode_lstm_step = 22 + 22\n",
    "n_decode_lstm_step = 22\n",
    "\n",
    "r_n_encode_lstm_step = 22\n",
    "r_n_decode_lstm_step = 22\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 500\n",
    "batch_size = config.batch_size\n",
    "reversed_batch_size = config.batch_size\n",
    "\n",
    "def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):\n",
    "    if not hasattr(sequences, '__len__'):\n",
    "        raise ValueError('`sequences` must be iterable.')\n",
    "    lengths = []\n",
    "    for x in sequences:\n",
    "        if not hasattr(x, '__len__'):\n",
    "            raise ValueError('`sequences` must be a list of iterables. '\n",
    "                             'Found non-iterable: ' + str(x))\n",
    "        lengths.append(len(x))\n",
    "\n",
    "    num_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x\n",
    "\n",
    "\"\"\" Extract only the vocabulary part of the data \"\"\"\n",
    "def refine(data):\n",
    "    words = re.findall(\"[a-zA-Z'-]+\", data)\n",
    "    words = [\"\".join(word.split(\"'\")) for word in words]\n",
    "    # words = [\"\".join(word.split(\"-\")) for word in words]\n",
    "    data = ' '.join(words)\n",
    "    return data\n",
    "\n",
    "def make_batch_X(batch_X, n_encode_lstm_step, dim_wordvec, word_vector, noise=False):\n",
    "    for i in range(len(batch_X)):\n",
    "        batch_X[i] = [word_vector[w] if w in word_vector else np.zeros(dim_wordvec) for w in batch_X[i]]\n",
    "        if noise:\n",
    "            batch_X[i].insert(0, np.random.normal(size=(dim_wordvec,))) # insert random normal at the first step\n",
    "\n",
    "        if len(batch_X[i]) > n_encode_lstm_step:\n",
    "            batch_X[i] = batch_X[i][:n_encode_lstm_step]\n",
    "        else:\n",
    "            for _ in range(len(batch_X[i]), n_encode_lstm_step):\n",
    "                batch_X[i].append(np.zeros(dim_wordvec))\n",
    "\n",
    "    current_feats = np.array(batch_X)\n",
    "    return current_feats\n",
    "\n",
    "def make_batch_Y(batch_Y, wordtoix, n_decode_lstm_step):\n",
    "    current_captions = batch_Y\n",
    "    current_captions = map(lambda x: '<bos> ' + x, current_captions)\n",
    "    current_captions = map(lambda x: x.replace('.', ''), current_captions)\n",
    "    current_captions = map(lambda x: x.replace(',', ''), current_captions)\n",
    "    current_captions = map(lambda x: x.replace('\"', ''), current_captions)\n",
    "    current_captions = map(lambda x: x.replace('\\n', ''), current_captions)\n",
    "    current_captions = map(lambda x: x.replace('?', ''), current_captions)\n",
    "    current_captions = map(lambda x: x.replace('!', ''), current_captions)\n",
    "    current_captions = map(lambda x: x.replace('\\\\', ''), current_captions)\n",
    "    current_captions = map(lambda x: x.replace('/', ''), current_captions)\n",
    "\n",
    "    for idx, each_cap in enumerate(current_captions):\n",
    "        word = each_cap.lower().split(' ')\n",
    "        if len(word) < n_decode_lstm_step:\n",
    "            current_captions[idx] = current_captions[idx] + ' <eos>'\n",
    "        else:\n",
    "            new_word = ''\n",
    "            for i in range(n_decode_lstm_step-1):\n",
    "                new_word = new_word + word[i] + ' '\n",
    "            current_captions[idx] = new_word + '<eos>'\n",
    "\n",
    "    current_caption_ind = []\n",
    "    for cap in current_captions:\n",
    "        current_word_ind = []\n",
    "        for word in cap.lower().split(' '):\n",
    "            if word in wordtoix:\n",
    "                current_word_ind.append(wordtoix[word])\n",
    "            else:\n",
    "                current_word_ind.append(wordtoix['<unk>'])\n",
    "        current_caption_ind.append(current_word_ind)\n",
    "\n",
    "    current_caption_matrix = pad_sequences(current_caption_ind, padding='post', maxlen=n_decode_lstm_step)\n",
    "    current_caption_matrix = np.hstack([current_caption_matrix, np.zeros([len(current_caption_matrix), 1])]).astype(int)\n",
    "    current_caption_masks = np.zeros((current_caption_matrix.shape[0], current_caption_matrix.shape[1]))\n",
    "    nonzeros = np.array(map(lambda x: (x != 0).sum() + 1, current_caption_matrix))\n",
    "\n",
    "    for ind, row in enumerate(current_caption_masks):\n",
    "        row[:nonzeros[ind]] = 1\n",
    "\n",
    "    return current_caption_matrix, current_caption_masks\n",
    "\n",
    "def index2sentence(generated_word_index, prob_logit, ixtoword):\n",
    "    # remove <unk> to second high prob. word\n",
    "    for i in range(len(generated_word_index)):\n",
    "        if generated_word_index[i] == 3 or generated_word_index[i] <= 1:\n",
    "            sort_prob_logit = sorted(prob_logit[i])\n",
    "            curindex = np.where(prob_logit[i] == sort_prob_logit[-2])[0][0]\n",
    "            count = 1\n",
    "            while curindex <= 3:\n",
    "                curindex = np.where(prob_logit[i] == sort_prob_logit[(-2)-count])[0][0]\n",
    "                count += 1\n",
    "\n",
    "            generated_word_index[i] = curindex\n",
    "\n",
    "    generated_words = []\n",
    "    for ind in generated_word_index:\n",
    "        generated_words.append(ixtoword[ind])\n",
    "\n",
    "    # generate sentence\n",
    "    punctuation = np.argmax(np.array(generated_words) == '<eos>') + 1\n",
    "    generated_words = generated_words[:punctuation]\n",
    "    generated_sentence = ' '.join(generated_words)\n",
    "\n",
    "    # modify the output sentence \n",
    "    generated_sentence = generated_sentence.replace('<bos> ', '')\n",
    "    generated_sentence = generated_sentence.replace('<eos>', '')\n",
    "    generated_sentence = generated_sentence.replace(' <eos>', '')\n",
    "    generated_sentence = generated_sentence.replace('--', '')\n",
    "    generated_sentence = generated_sentence.split('  ')\n",
    "    for i in range(len(generated_sentence)):\n",
    "        generated_sentence[i] = generated_sentence[i].strip()\n",
    "        if len(generated_sentence[i]) > 1:\n",
    "            generated_sentence[i] = generated_sentence[i][0].upper() + generated_sentence[i][1:] + '.'\n",
    "        else:\n",
    "            generated_sentence[i] = generated_sentence[i].upper()\n",
    "    generated_sentence = ' '.join(generated_sentence)\n",
    "    generated_sentence = generated_sentence.replace(' i ', ' I ')\n",
    "    generated_sentence = generated_sentence.replace(\"i'm\", \"I'm\")\n",
    "    generated_sentence = generated_sentence.replace(\"i'd\", \"I'd\")\n",
    "\n",
    "    return generated_sentence\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def count_rewards(dull_loss, forward_entropy, backward_entropy, forward_target, backward_target, reward_type='pg'):\n",
    "    ''' args:\n",
    "            generated_word_indexs:  <type 'numpy.ndarray'>  \n",
    "                                    word indexs generated by pre-trained model\n",
    "                                    shape: (batch_size, n_decode_lstm_step)\n",
    "            inference_feats:        <type 'dict'>  \n",
    "                                    some features generated during inference\n",
    "                                    keys:\n",
    "                                        'probs': \n",
    "                                            shape: (n_decode_lstm_step, batch_size, n_words)\n",
    "                                        'embeds': \n",
    "                                            shape: (n_decode_lstm_step, batch_size, dim_hidden)\n",
    "                                            current word embeddings at each decode stage\n",
    "                                        'states': \n",
    "                                            shape: (n_encode_lstm_step, batch_size, dim_hidden)\n",
    "                                            LSTM_1's hidden state at each encode stage\n",
    "    '''\n",
    "\n",
    "    # normal training, rewards all equal to 1\n",
    "    if reward_type == 'normal':\n",
    "        return np.ones([batch_size, n_decode_lstm_step])\n",
    "\n",
    "    if reward_type == 'pg':\n",
    "        forward_entropy = np.array(forward_entropy).reshape(batch_size, n_decode_lstm_step)\n",
    "        backward_entropy = np.array(backward_entropy).reshape(batch_size, n_decode_lstm_step)\n",
    "        total_loss = np.zeros([batch_size, n_decode_lstm_step])\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # ease of answering\n",
    "            total_loss[i, :] += dull_loss[i]\n",
    "    \n",
    "            # information flow\n",
    "            # cosine_sim = 1 - spatial.distance.cosine(embeds[0][-1], embeds[1][-1])\n",
    "            # IF = cosine_sim * (-1)\n",
    "    \n",
    "            # semantic coherence\n",
    "            forward_len = len(forward_target[i].split())\n",
    "            backward_len = len(backward_target[i].split())\n",
    "            if forward_len > 0:\n",
    "                total_loss[i, :] += (np.sum(forward_entropy[i]) / forward_len)\n",
    "            if backward_len > 0:\n",
    "                total_loss[i, :] += (np.sum(backward_entropy[i]) / backward_len)\n",
    "\n",
    "        total_loss = sigmoid(total_loss) * 1.1\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "def train():\n",
    "    global dull_set\n",
    "\n",
    "    wordtoix, ixtoword, bias_init_vector = data_parser.preProBuildWordVocab(word_count_threshold=word_count_threshold)\n",
    "    word_vector = KeyedVectors.load_word2vec_format('model/word_vector.bin', binary=True)\n",
    "\n",
    "    if len(dull_set) > batch_size:\n",
    "        dull_set = dull_set[:batch_size]\n",
    "    else:\n",
    "        for _ in range(len(dull_set), batch_size):\n",
    "            dull_set.append('')\n",
    "    dull_matrix, dull_mask = make_batch_Y(\n",
    "                                batch_Y=dull_set, \n",
    "                                wordtoix=wordtoix, \n",
    "                                n_decode_lstm_step=n_decode_lstm_step)\n",
    "\n",
    "    ones_reward = np.ones([batch_size, n_decode_lstm_step])\n",
    "\n",
    "    g1 = tf.Graph()\n",
    "    g2 = tf.Graph()\n",
    "\n",
    "    default_graph = tf.get_default_graph() \n",
    "\n",
    "    with g1.as_default():\n",
    "        model = PolicyGradient_chatbot(\n",
    "                dim_wordvec=dim_wordvec,\n",
    "                n_words=len(wordtoix),\n",
    "                dim_hidden=dim_hidden,\n",
    "                batch_size=batch_size,\n",
    "                n_encode_lstm_step=n_encode_lstm_step,\n",
    "                n_decode_lstm_step=n_decode_lstm_step,\n",
    "                bias_init_vector=bias_init_vector,\n",
    "                lr=learning_rate)\n",
    "        train_op, loss, input_tensors, inter_value = model.build_model()\n",
    "        tf_states, tf_actions, tf_feats = model.build_generator()\n",
    "        sess = tf.InteractiveSession()\n",
    "        saver = tf.train.Saver(max_to_keep=100)\n",
    "        if checkpoint:\n",
    "            print(\"Use Model {}.\".format(model_name))\n",
    "            saver.restore(sess, os.path.join(model_path, model_name))\n",
    "            print(\"Model {} restored.\".format(model_name))\n",
    "        else:\n",
    "            print(\"Restart training...\")\n",
    "            tf.global_variables_initializer().run()\n",
    "\n",
    "    r_wordtoix, r_ixtoword, r_bias_init_vector = data_parser.preProBuildWordVocab(word_count_threshold=r_word_count_threshold)\n",
    "    with g2.as_default():\n",
    "        reversed_model = Seq2Seq_chatbot(\n",
    "            dim_wordvec=dim_wordvec,\n",
    "            n_words=len(r_wordtoix),\n",
    "            dim_hidden=dim_hidden,\n",
    "            batch_size=reversed_batch_size,\n",
    "            n_encode_lstm_step=r_n_encode_lstm_step,\n",
    "            n_decode_lstm_step=r_n_decode_lstm_step,\n",
    "            bias_init_vector=r_bias_init_vector,\n",
    "            lr=learning_rate)\n",
    "        _, _, word_vectors, caption, caption_mask, reverse_inter = reversed_model.build_model()\n",
    "        sess2 = tf.InteractiveSession()\n",
    "        saver2 = tf.train.Saver()\n",
    "        saver2.restore(sess2, os.path.join(reversed_model_path, reversed_model_name))\n",
    "        print(\"Reversed model {} restored.\".format(reversed_model_name))\n",
    "\n",
    "\n",
    "    dr = Data_Reader(cur_train_index=config.cur_train_index, load_list=config.load_list)\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        n_batch = dr.get_batch_num(batch_size)\n",
    "        sb = start_batch if epoch == start_epoch else 0\n",
    "        for batch in range(sb, n_batch):\n",
    "            start_time = time.time()\n",
    "\n",
    "            batch_X, batch_Y, former = dr.generate_training_batch_with_former(batch_size)\n",
    "\n",
    "            current_feats = make_batch_X(\n",
    "                            batch_X=copy.deepcopy(batch_X), \n",
    "                            n_encode_lstm_step=n_encode_lstm_step, \n",
    "                            dim_wordvec=dim_wordvec,\n",
    "                            word_vector=word_vector)\n",
    "\n",
    "            current_caption_matrix, current_caption_masks = make_batch_Y(\n",
    "                                                                batch_Y=copy.deepcopy(batch_Y), \n",
    "                                                                wordtoix=wordtoix, \n",
    "                                                                n_decode_lstm_step=n_decode_lstm_step)\n",
    "\n",
    "            if training_type == 'pg':\n",
    "                # action: generate batch_size sents\n",
    "                action_word_indexs, inference_feats = sess.run([tf_actions, tf_feats],\n",
    "                                                                feed_dict={\n",
    "                                                                   tf_states: current_feats\n",
    "                                                                })\n",
    "                action_word_indexs = np.array(action_word_indexs).reshape(batch_size, n_decode_lstm_step)\n",
    "                action_probs = np.array(inference_feats['probs']).reshape(batch_size, n_decode_lstm_step, -1)\n",
    "\n",
    "                actions = []\n",
    "                actions_list = []\n",
    "                for i in range(len(action_word_indexs)):\n",
    "                    action = index2sentence(\n",
    "                                generated_word_index=action_word_indexs[i], \n",
    "                                prob_logit=action_probs[i],\n",
    "                                ixtoword=ixtoword)\n",
    "                    actions.append(action)\n",
    "                    actions_list.append(action.split())\n",
    "\n",
    "                action_feats = make_batch_X(\n",
    "                                batch_X=copy.deepcopy(actions_list), \n",
    "                                n_encode_lstm_step=n_encode_lstm_step, \n",
    "                                dim_wordvec=dim_wordvec,\n",
    "                                word_vector=word_vector)\n",
    "\n",
    "                action_caption_matrix, action_caption_masks = make_batch_Y(\n",
    "                                                                batch_Y=copy.deepcopy(actions), \n",
    "                                                                wordtoix=wordtoix, \n",
    "                                                                n_decode_lstm_step=n_decode_lstm_step)\n",
    "\n",
    "                # ease of answering\n",
    "                dull_loss = []\n",
    "                for vector in action_feats:\n",
    "                    action_batch_X = np.array([vector for _ in range(batch_size)])\n",
    "                    d_loss = sess.run(loss,\n",
    "                                 feed_dict={\n",
    "                                    input_tensors['word_vectors']: action_batch_X,\n",
    "                                    input_tensors['caption']: dull_matrix,\n",
    "                                    input_tensors['caption_mask']: dull_mask,\n",
    "                                    input_tensors['reward']: ones_reward\n",
    "                                })\n",
    "                    d_loss = d_loss * -1. / len(dull_set)\n",
    "                    dull_loss.append(d_loss)\n",
    "\n",
    "                # Information Flow\n",
    "                pass\n",
    "\n",
    "                # semantic coherence\n",
    "                forward_inter = sess.run(inter_value,\n",
    "                                 feed_dict={\n",
    "                                    input_tensors['word_vectors']: current_feats,\n",
    "                                    input_tensors['caption']: action_caption_matrix,\n",
    "                                    input_tensors['caption_mask']: action_caption_masks,\n",
    "                                    input_tensors['reward']: ones_reward\n",
    "                                })\n",
    "                forward_entropies = forward_inter['entropies']\n",
    "                former_caption_matrix, former_caption_masks = make_batch_Y(\n",
    "                                                                batch_Y=copy.deepcopy(former), \n",
    "                                                                wordtoix=wordtoix, \n",
    "                                                                n_decode_lstm_step=n_decode_lstm_step)\n",
    "                action_feats = make_batch_X(\n",
    "                                batch_X=copy.deepcopy(actions_list), \n",
    "                                n_encode_lstm_step=r_n_encode_lstm_step, \n",
    "                                dim_wordvec=dim_wordvec,\n",
    "                                word_vector=word_vector)\n",
    "                backward_inter = sess2.run(reverse_inter,\n",
    "                                 feed_dict={\n",
    "                                    word_vectors: action_feats,\n",
    "                                    caption: former_caption_matrix,\n",
    "                                    caption_mask: former_caption_masks\n",
    "                                })\n",
    "                backward_entropies = backward_inter['entropies']\n",
    "\n",
    "                # reward: count goodness of actions\n",
    "                rewards = count_rewards(dull_loss, forward_entropies, backward_entropies, actions, former, reward_type='pg')\n",
    "    \n",
    "                # policy gradient: train batch with rewards\n",
    "                if batch % 10 == 0:\n",
    "                    _, loss_val = sess.run(\n",
    "                            [train_op, loss],\n",
    "                            feed_dict={\n",
    "                                input_tensors['word_vectors']: current_feats,\n",
    "                                input_tensors['caption']: current_caption_matrix,\n",
    "                                input_tensors['caption_mask']: current_caption_masks,\n",
    "                                input_tensors['reward']: rewards\n",
    "                            })\n",
    "                    print(\"Epoch: {}, batch: {}, loss: {}, Elapsed time: {}\".format(epoch, batch, loss_val, time.time() - start_time))\n",
    "                else:\n",
    "                    _ = sess.run(train_op,\n",
    "                                 feed_dict={\n",
    "                                    input_tensors['word_vectors']: current_feats,\n",
    "                                    input_tensors['caption']: current_caption_matrix,\n",
    "                                    input_tensors['caption_mask']: current_caption_masks,\n",
    "                                    input_tensors['reward']: rewards\n",
    "                                })\n",
    "                if batch % 1000 == 0 and batch != 0:\n",
    "                    print(\"Epoch {} batch {} is done. Saving the model ...\".format(epoch, batch))\n",
    "                    saver.save(sess, os.path.join(model_path, 'model-{}-{}'.format(epoch, batch)))\n",
    "            if training_type == 'normal':\n",
    "                if batch % 10 == 0:\n",
    "                    _, loss_val = sess.run(\n",
    "                            [train_op, loss],\n",
    "                            feed_dict={\n",
    "                                input_tensors['word_vectors']: current_feats,\n",
    "                                input_tensors['caption']: current_caption_matrix,\n",
    "                                input_tensors['caption_mask']: current_caption_masks,\n",
    "                                input_tensors['reward']: ones_reward\n",
    "                            })\n",
    "                    print(\"Epoch: {}, batch: {}, loss: {}, Elapsed time: {}\".format(epoch, batch, loss_val, time.time() - start_time))\n",
    "                else:\n",
    "                    _ = sess.run(train_op,\n",
    "                                 feed_dict={\n",
    "                                    input_tensors['word_vectors']: current_feats,\n",
    "                                    input_tensors['caption']: current_caption_matrix,\n",
    "                                    input_tensors['caption_mask']: current_caption_masks,\n",
    "                                    input_tensors['reward']: ones_reward\n",
    "                                })\n",
    "\n",
    "        print(\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
    "        saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/download_reversed.sh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/test_RL.sh <PATH TO MODEL> <INPUT FILE> <OUTPUT FILE>\n",
    "\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"python\")\n",
    "import data_parser\n",
    "import config\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from rl_model import PolicyGradient_chatbot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#=====================================================\n",
    "# Global Parameters\n",
    "#=====================================================\n",
    "default_model_path = './model/RL/model-56-3000'\n",
    "testing_data_path = 'sample_input.txt' if len(sys.argv) <= 2 else sys.argv[2]\n",
    "output_path = 'sample_output_RL.txt' if len(sys.argv) <= 3 else sys.argv[3]\n",
    "\n",
    "word_count_threshold = config.WC_threshold\n",
    "\n",
    "#=====================================================\n",
    "# Train Parameters\n",
    "#=====================================================\n",
    "dim_wordvec = 300\n",
    "dim_hidden = 1000\n",
    "\n",
    "n_encode_lstm_step = 22 + 1 # one random normal as the first timestep\n",
    "n_decode_lstm_step = 22\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "\"\"\" Extract only the vocabulary part of the data \"\"\"\n",
    "def refine(data):\n",
    "    words = re.findall(\"[a-zA-Z'-]+\", data)\n",
    "    words = [\"\".join(word.split(\"'\")) for word in words]\n",
    "    # words = [\"\".join(word.split(\"-\")) for word in words]\n",
    "    data = ' '.join(words)\n",
    "    return data\n",
    "\n",
    "def test(model_path=default_model_path):\n",
    "    testing_data = open(testing_data_path, 'r').read().split('\\n')\n",
    "\n",
    "    word_vector = KeyedVectors.load_word2vec_format('model/word_vector.bin', binary=True)\n",
    "\n",
    "    _, ixtoword, bias_init_vector = data_parser.preProBuildWordVocab(word_count_threshold=word_count_threshold)\n",
    "\n",
    "    model = PolicyGradient_chatbot(\n",
    "            dim_wordvec=dim_wordvec,\n",
    "            n_words=len(ixtoword),\n",
    "            dim_hidden=dim_hidden,\n",
    "            batch_size=batch_size,\n",
    "            n_encode_lstm_step=n_encode_lstm_step,\n",
    "            n_decode_lstm_step=n_decode_lstm_step,\n",
    "            bias_init_vector=bias_init_vector)\n",
    "\n",
    "    word_vectors, caption_tf, feats = model.build_generator()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    try:\n",
    "        print('\\n=== Use model', model_path, '===\\n')\n",
    "        saver.restore(sess, model_path)\n",
    "    except:\n",
    "        print('\\nUse default model\\n')\n",
    "        saver.restore(sess, default_model_path)\n",
    "\n",
    "    with open(output_path, 'w') as out:\n",
    "        generated_sentences = []\n",
    "        bleu_score_avg = [0., 0.]\n",
    "        for idx, question in enumerate(testing_data):\n",
    "            print('question =>', question)\n",
    "\n",
    "            question = [refine(w) for w in question.lower().split()]\n",
    "            question = [word_vector[w] if w in word_vector else np.zeros(dim_wordvec) for w in question]\n",
    "            question.insert(0, np.random.normal(size=(dim_wordvec,))) # insert random normal at the first step\n",
    "\n",
    "            if len(question) > n_encode_lstm_step:\n",
    "                question = question[:n_encode_lstm_step]\n",
    "            else:\n",
    "                for _ in range(len(question), n_encode_lstm_step):\n",
    "                    question.append(np.zeros(dim_wordvec))\n",
    "\n",
    "            question = np.array([question]) # 1x22x300\n",
    "    \n",
    "            generated_word_index, prob_logit = sess.run([caption_tf, feats['probs']], feed_dict={word_vectors: question})\n",
    "            generated_word_index = np.array(generated_word_index).reshape(batch_size, n_decode_lstm_step)[0]\n",
    "            prob_logit = np.array(prob_logit).reshape(batch_size, n_decode_lstm_step, -1)[0]\n",
    "            # print('generated_word_index.shape', generated_word_index.shape)\n",
    "            # print('prob_logit.shape', prob_logit.shape)\n",
    "\n",
    "            # remove <unk> to second high prob. word\n",
    "            # print('generated_word_index', generated_word_index)\n",
    "            for i in range(len(generated_word_index)):\n",
    "                if generated_word_index[i] == 3:\n",
    "                    sort_prob_logit = sorted(prob_logit[i])\n",
    "                    # print('max val', sort_prob_logit[-1])\n",
    "                    # print('second max val', sort_prob_logit[-2])\n",
    "                    maxindex = np.where(prob_logit[i] == sort_prob_logit[-1])[0][0]\n",
    "                    secmaxindex = np.where(prob_logit[i] == sort_prob_logit[-2])[0][0]\n",
    "                    # print('max ind', maxindex, ixtoword[maxindex])\n",
    "                    # print('second max ind', secmaxindex, ixtoword[secmaxindex])\n",
    "                    generated_word_index[i] = secmaxindex\n",
    "            # print('generated_word_index', generated_word_index)\n",
    "\n",
    "            generated_words = []\n",
    "            for ind in generated_word_index:\n",
    "                generated_words.append(ixtoword[ind])\n",
    "\n",
    "            # generate sentence\n",
    "            punctuation = np.argmax(np.array(generated_words) == '<eos>') + 1\n",
    "            generated_words = generated_words[:punctuation]\n",
    "            generated_sentence = ' '.join(generated_words)\n",
    "\n",
    "            # modify the output sentence \n",
    "            generated_sentence = generated_sentence.replace('<bos> ', '')\n",
    "            generated_sentence = generated_sentence.replace(' <eos>', '')\n",
    "            generated_sentence = generated_sentence.replace('--', '')\n",
    "            generated_sentence = generated_sentence.split('  ')\n",
    "            for i in range(len(generated_sentence)):\n",
    "                generated_sentence[i] = generated_sentence[i].strip()\n",
    "                if len(generated_sentence[i]) > 1:\n",
    "                    generated_sentence[i] = generated_sentence[i][0].upper() + generated_sentence[i][1:] + '.'\n",
    "                else:\n",
    "                    generated_sentence[i] = generated_sentence[i].upper()\n",
    "            generated_sentence = ' '.join(generated_sentence)\n",
    "            generated_sentence = generated_sentence.replace(' i ', ' I ')\n",
    "            generated_sentence = generated_sentence.replace(\"i'm\", \"I'm\")\n",
    "            generated_sentence = generated_sentence.replace(\"i'd\", \"I'd\")\n",
    "            generated_sentence = generated_sentence.replace(\"i'll\", \"I'll\")\n",
    "            generated_sentence = generated_sentence.replace(\"i'v\", \"I'v\")\n",
    "            generated_sentence = generated_sentence.replace(\" - \", \"\")\n",
    "\n",
    "            print('generated_sentence =>', generated_sentence)\n",
    "            out.write(generated_sentence + '\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) > 1:\n",
    "        test(model_path=sys.argv[1])\n",
    "    else:\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "./script/simulate.sh <PATH TO MODEL> <SIMULATE TYPE> <INPUT FILE> <OUTPUT FILE>\n",
    "\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import data_parser\n",
    "import config\n",
    "\n",
    "from model import Seq2Seq_chatbot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "#=====================================================\n",
    "# Global Parameters\n",
    "#=====================================================\n",
    "default_model_path = './model/model-20'\n",
    "default_simulate_type = 1  # type 1 use one former sent, type 2 use two former sents\n",
    "\n",
    "testing_data_path = 'sample_input.txt' if len(sys.argv) <= 3 else sys.argv[3]\n",
    "output_path = 'sample_dialog_output.txt' if len(sys.argv) <= 4 else sys.argv[4]\n",
    "\n",
    "max_turns = config.MAX_TURNS\n",
    "word_count_threshold = config.WC_threshold\n",
    "\n",
    "#=====================================================\n",
    "# Train Parameters\n",
    "#=====================================================\n",
    "dim_wordvec = 300\n",
    "dim_hidden = 1000\n",
    "\n",
    "n_encode_lstm_step = 22  # need to plus 1 later, because one random normal as the first timestep\n",
    "n_decode_lstm_step = 22\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "\"\"\" Extract only the vocabulary part of the data \"\"\"\n",
    "def refine(data):\n",
    "    words = re.findall(\"[a-zA-Z'-]+\", data)\n",
    "    words = [\"\".join(word.split(\"'\")) for word in words]\n",
    "    # words = [\"\".join(word.split(\"-\")) for word in words]\n",
    "    data = ' '.join(words)\n",
    "    return data\n",
    "\n",
    "def generate_question_vector(state, word_vector, dim_wordvec, n_encode_lstm_step):\n",
    "    state = [refine(w) for w in state.lower().split()]\n",
    "    state = [word_vector[w] if w in word_vector else np.zeros(dim_wordvec) for w in state]\n",
    "    state.insert(0, np.random.normal(size=(dim_wordvec,))) # insert random normal at the first step\n",
    "\n",
    "    if len(state) > n_encode_lstm_step:\n",
    "        state = state[:n_encode_lstm_step]\n",
    "    else:\n",
    "        for _ in range(len(state), n_encode_lstm_step):\n",
    "            state.append(np.zeros(dim_wordvec))\n",
    "\n",
    "    return np.array([state]) # 1 x n_encode_lstm_step x dim_wordvec\n",
    "\n",
    "def generate_answer_sentence(generated_word_index, prob_logit, ixtoword):\n",
    "    # remove <unk> to second high prob. word\n",
    "    for i in range(len(generated_word_index)):\n",
    "        if generated_word_index[i] == 3:\n",
    "            sort_prob_logit = sorted(prob_logit[i][0])\n",
    "            # print('max val', sort_prob_logit[-1])\n",
    "            # print('second max val', sort_prob_logit[-2])\n",
    "            maxindex = np.where(prob_logit[i][0] == sort_prob_logit[-1])[0][0]\n",
    "            secmaxindex = np.where(prob_logit[i][0] == sort_prob_logit[-2])[0][0]\n",
    "            # print('max ind', maxindex, ixtoword[maxindex])\n",
    "            # print('second max ind', secmaxindex, ixtoword[secmaxindex])\n",
    "            generated_word_index[i] = secmaxindex\n",
    "\n",
    "    generated_words = []\n",
    "    for ind in generated_word_index:\n",
    "        generated_words.append(ixtoword[ind])\n",
    "\n",
    "    # generate sentence\n",
    "    punctuation = np.argmax(np.array(generated_words) == '<eos>') + 1\n",
    "    generated_words = generated_words[:punctuation]\n",
    "    generated_sentence = ' '.join(generated_words)\n",
    "\n",
    "    # modify the output sentence \n",
    "    generated_sentence = generated_sentence.replace('<bos> ', '')\n",
    "    generated_sentence = generated_sentence.replace(' <eos>', '')\n",
    "    generated_sentence = generated_sentence.replace('--', '')\n",
    "    generated_sentence = generated_sentence.split('  ')\n",
    "    for i in range(len(generated_sentence)):\n",
    "        generated_sentence[i] = generated_sentence[i].strip()\n",
    "        if len(generated_sentence[i]) > 1:\n",
    "            generated_sentence[i] = generated_sentence[i][0].upper() + generated_sentence[i][1:] + '.'\n",
    "        else:\n",
    "            generated_sentence[i] = generated_sentence[i].upper()\n",
    "    generated_sentence = ' '.join(generated_sentence)\n",
    "    generated_sentence = generated_sentence.replace(' i ', ' I ')\n",
    "    generated_sentence = generated_sentence.replace(\"i'm\", \"I'm\")\n",
    "    generated_sentence = generated_sentence.replace(\"i'd\", \"I'd\")\n",
    "\n",
    "    return generated_sentence\n",
    "\n",
    "def init_history(simulate_type, start_sentence):\n",
    "    history = []\n",
    "    history += ['' for _ in range(simulate_type-1)]\n",
    "    history.append(start_sentence)\n",
    "    return history\n",
    "\n",
    "def get_cur_state(simulate_type, dialog_history):\n",
    "    return ' '.join(dialog_history[-1*simulate_type:]).strip()\n",
    "\n",
    "def simulate(model_path=default_model_path, simulate_type=default_simulate_type):\n",
    "    ''' args:\n",
    "            model_path:     <type 'str'> the pre-trained model using for inference\n",
    "            simulate_type:  <type 'int'> how many former sents should use as state\n",
    "    '''\n",
    "\n",
    "    testing_data = open(testing_data_path, 'r').read().split('\\n')\n",
    "\n",
    "    word_vector = KeyedVectors.load_word2vec_format('model/word_vector.bin', binary=True)\n",
    "\n",
    "    _, ixtoword, bias_init_vector = data_parser.preProBuildWordVocab(word_count_threshold=word_count_threshold)\n",
    "\n",
    "    model = Seq2Seq_chatbot(\n",
    "            dim_wordvec=dim_wordvec,\n",
    "            n_words=len(ixtoword),\n",
    "            dim_hidden=dim_hidden,\n",
    "            batch_size=batch_size,\n",
    "            n_encode_lstm_step=n_encode_lstm_step,\n",
    "            n_decode_lstm_step=n_decode_lstm_step,\n",
    "            bias_init_vector=bias_init_vector)\n",
    "\n",
    "    word_vectors, caption_tf, probs, _ = model.build_generator()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    try:\n",
    "        print('\\n=== Use model {} ===\\n'.format(model_path))\n",
    "        saver.restore(sess, model_path)\n",
    "    except:\n",
    "        print('\\nUse default model\\n')\n",
    "        saver.restore(sess, default_model_path)\n",
    "\n",
    "    with open(output_path, 'w') as out:\n",
    "        for idx, start_sentence in enumerate(testing_data):\n",
    "            print('dialog {}'.format(idx))\n",
    "            print('A => {}'.format(start_sentence))\n",
    "            out.write('dialog {}\\nA: {}\\n'.format(idx, start_sentence))\n",
    "\n",
    "            dialog_history = init_history(simulate_type, start_sentence)\n",
    "\n",
    "            for turn in range(max_turns):\n",
    "                question = generate_question_vector(state=get_cur_state(simulate_type, dialog_history), \n",
    "                                                    word_vector=word_vector, \n",
    "                                                    dim_wordvec=dim_wordvec, \n",
    "                                                    n_encode_lstm_step=n_encode_lstm_step)\n",
    "\n",
    "                generated_word_index, prob_logit = sess.run([caption_tf, probs], feed_dict={word_vectors: question})\n",
    "\n",
    "                generated_sentence = generate_answer_sentence(generated_word_index=generated_word_index, \n",
    "                                                              prob_logit=prob_logit, \n",
    "                                                              ixtoword=ixtoword)\n",
    "\n",
    "                dialog_history.append(generated_sentence)\n",
    "                print('B => {}'.format(generated_sentence))\n",
    "\n",
    "                question_2 = generate_question_vector(state=get_cur_state(simulate_type, dialog_history), \n",
    "                                                    word_vector=word_vector, \n",
    "                                                    dim_wordvec=dim_wordvec, \n",
    "                                                    n_encode_lstm_step=n_encode_lstm_step)\n",
    "\n",
    "                generated_word_index, prob_logit = sess.run([caption_tf, probs], feed_dict={word_vectors: question_2})\n",
    "\n",
    "                generated_sentence_2 = generate_answer_sentence(generated_word_index=generated_word_index, \n",
    "                                                                  prob_logit=prob_logit, \n",
    "                                                                  ixtoword=ixtoword)\n",
    "\n",
    "                dialog_history.append(generated_sentence_2)\n",
    "                print('A => {}'.format(generated_sentence_2))\n",
    "                out.write('B: {}\\nA: {}\\n'.format(generated_sentence, generated_sentence_2))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = default_model_path if len(sys.argv) <= 1 else sys.argv[1]\n",
    "    simulate_type = default_simulate_type if len(sys.argv) <= 2 else int(sys.argv[2])\n",
    "    n_encode_lstm_step = n_encode_lstm_step * simulate_type + 1  # sent len * sent num + one random normal\n",
    "    print('simulate_type', simulate_type)\n",
    "    print('n_encode_lstm_step', n_encode_lstm_step)\n",
    "    simulate(model_path=model_path, simulate_type=simulate_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dialog 0\n",
    "A: How are you?\n",
    "B: Very well thank you.\n",
    "A: I had an appointment at this afternoon. I wasn't wondering it's here. And i.\n",
    "B: Yes it's a little strange.\n",
    "A: You have to remember that perhaps a young one.\n",
    "B: Yes.\n",
    "A: What had like like that.\n",
    "B: But there were a lot of things outside.\n",
    "A: Tell me what to do in.\n",
    "B: Well.\n",
    "A: Tell him what to do.\n",
    "B: That's what I'm here for bob and he's got it.\n",
    "A: Do what you can make him in your head.\n",
    "B: Huh.\n",
    "A: So when was the last time you saw him.\n",
    "B: Oh god I didn't know. Where's my hair. What's wrong.\n",
    "A: The wrong number.\n",
    "B: Don't start ridiculous.\n",
    "A: Now don't be ridiculous.\n",
    "B: Why are you telling him he's afraid of evidence.\n",
    "A: I'm not want to discuss out before you do something.\n",
    "dialog 1\n",
    "A: What's your name?\n",
    "B: Sir smith.\n",
    "A: What are you doing here.\n",
    "B: Must be some.\n",
    "A: I am.\n",
    "B: You can start to take a cab in my next room if you want to.\n",
    "A: Why.\n",
    "B: I thought you'd make a deal.\n",
    "A: You're saying the wrong guy.\n",
    "B: What do you mean.\n",
    "A: You haven't talked to him since he got.\n",
    "B: Oh yeah. That was me.\n",
    "A: The we.\n",
    "B: Yeah.\n",
    "A: Jesus. It's a long way. Now we're talking about four and five guys a week no.\n",
    "B: You mean a little.\n",
    "A: Yeah a real nice.\n",
    "B: Well thanks a lot.\n",
    "A: I'll try to be able to say what things happen.\n",
    "B: I don't know.\n",
    "A: You don't understand. You would have done for you sid. You wouldn't that a million times.\n",
    "dialog 2\n",
    "A: Hello\n",
    "B: I'm sorry. The answer didn't seem in. \n",
    "A: I'm glad you're right.\n",
    "B: It's not that kind of a woman's joke.\n",
    "A: You're a good boy.\n",
    "B: Let's hope because we're not gonna make you happy mate.\n",
    "A: I'm fine.\n",
    "B: Happy birthday.\n",
    "A: Oh. Well. I wouldn't mind if we were just.\n",
    "B: I'm sorry I didn't mean it.\n",
    "A: My goodness you see again. And I'm just going to have to get you out. I i.\n",
    "B: You never came to make it seems.\n",
    "A: Yeah I know it's not.\n",
    "B: I know dad. I can say it but I never heard it was.\n",
    "A: What can you think of it. It's why they call you that monster.\n",
    "B: You told me about it. You know.\n",
    "A: So who is this.\n",
    "B: You know who I am. It's just the one I want.\n",
    "A: I'm glad you.\n",
    "B: Oh come on.\n",
    "A: What.\n",
    "dialog 3\n",
    "A: Thank God!  If I had to hear one more story about your coiffure\n",
    "B: My mom had a little strange experience with mother.\n",
    "A: What happened.\n",
    "B: Last time.\n",
    "A: I didn't want to.\n",
    "B: But you never do better.\n",
    "A: You don't.\n",
    "B: Yeah maybe.\n",
    "A: Boy you should be up okay but we're not going to talk.\n",
    "B: Sure.\n",
    "A: Do you want to come over looking for someone.\n",
    "B: Hi I'm in a dance.\n",
    "A: I'm in late.\n",
    "B: Oh I thought you was a very popular girl here I mean running away.\n",
    "A: I'm sorry I didn't mean to.\n",
    "B: I'm sorry it's the whole thing that happened it.\n",
    "A: I\n",
    "B: No just fine.\n",
    "A: Okay. Come on it's graduation.\n",
    "B: What.\n",
    "A: It's a surprise. Come on go ask.\n",
    "dialog 4\n",
    "A: You never wanted to go out with me, did you?\n",
    "B: No I didn't.\n",
    "A: You said you liked jimmy.\n",
    "B: No I was a great white man i've had some fucked to.\n",
    "A: What about that guy.\n",
    "B: He never really like that way.\n",
    "A: What.\n",
    "B: They just want to come here.\n",
    "A: If we.\n",
    "B: If it's okay with you it's not as far as I'm concerned that.\n",
    "A: I wish I'd stay here for a little while while about the night.\n",
    "B: Oh there's nothing I can think about.\n",
    "A: I just don't know if that's the time you want to be I don't know what's happening.\n",
    "B: What happened at the time.\n",
    "A: The point on the beach.\n",
    "B: It isn't for a book. I was just going to see if it was left but we found it.\n",
    "A: Yeah we were right in the middle of the night as my head. Why don't you take your hand.\n",
    "B: If the phone has no ears you know.\n",
    "A: Suppose you wanted to know how it was you that you tried to save his own everything.\n",
    "B: Yes. But I was a hard time. Ever since he's been a real decent man.\n",
    "A: No. He seems to think fast. I'm telling you.\n",
    "dialog 5\n",
    "A: I guess I thought I was protecting you.\n",
    "B: They don't need me just to go to trial.\n",
    "A: Should i.\n",
    "B: No I want to look at something okay.\n",
    "A: Get away from me.\n",
    "B: What.\n",
    "A: I want you to on the phone.\n",
    "B: What.\n",
    "A: Just don't go on me.\n",
    "B: What does it mean. What does it take. It's the. I mean since your story was.\n",
    "A: And what are the people dying to do to get it.\n",
    "B: You and me.\n",
    "A: Trust you.\n",
    "B: You can't.\n",
    "A: No not.\n",
    "B: You don't have a choice.\n",
    "A: Don't worry. We have enough time to discuss this.\n",
    "B: But I'm not my mother now.\n",
    "A: Jack I'm calling you out of the house.\n",
    "B: What.\n",
    "A: The money. I'm here.\n",
    "dialog 6\n",
    "A: Forget his reputation.  Do you think we've got a plan or not?\n",
    "B: You don't know.\n",
    "A: Don't worry about it. I'll get the story.\n",
    "B: What are you talking about.\n",
    "A: When you have children don't you go away.\n",
    "B: How come you're still in.\n",
    "A: I'll tell you later.\n",
    "B: You're in a great deal there.\n",
    "A: Yeah. See that road.\n",
    "B: Oh sure.\n",
    "A: Let's go look at the sand keep going to see if she's really making that line again.\n",
    "B: It's a good thing isn't just a little bit much better.\n",
    "A: What.\n",
    "B: I don't know if it's worth of nature.\n",
    "A: Well it isn't. <u>you<u> think about it. What's it about.\n",
    "B: What's that.\n",
    "A: Oh it's not mine it's all it's like it's got something.\n",
    "B: It's just the same way. I mean no wonder what the is.\n",
    "A: Yeah. Things.\n",
    "B: You don't remember anything.\n",
    "A: What's he like.\n",
    "dialog 7\n",
    "A: You didn't have a choice?\n",
    "B: They didn't take the job.\n",
    "A: Oh no. It's not that big deal. Let's go didn't make nice.\n",
    "B: I know it's not the same.\n",
    "A: I know the.\n",
    "B: Thanks.\n",
    "A: So do i.\n",
    "B: I've been saying it's all along to work out here jack you you're talking about.\n",
    "A: You have a few of his friends so he had no business would you like to go to.\n",
    "B: Oh yes. I can't just let you out without the rest of my life.\n",
    "A: Well it didn't show up that you know exactly what they say.\n",
    "B: I'm sorry I'm sorry. I'm sorry. I'm not.\n",
    "A: I know you do. But you gave a life up. It all sounds.\n",
    "B: Not exactly what I did yesterday.\n",
    "A: But if it did.\n",
    "B: Where.\n",
    "A: Two minutes before.\n",
    "B: How many men.\n",
    "A: Four. Six hundred and two you.\n",
    "B: Two.\n",
    "A: Shit and that shop.\n",
    "dialog 8\n",
    "A: Can you do me a favor?\n",
    "B: What.\n",
    "A: Have a good night with that girl who ever think of name that money were gonna do or later until.\n",
    "B: What.\n",
    "A: The first of those two questions of a wet and and there away.\n",
    "B: I was told.\n",
    "A: That's it the end of the little best you can sleep with all your body and hope still work.\n",
    "B: It's impossible.\n",
    "A: Maybe it's not the problem I am.\n",
    "B: It's not a fucking job.\n",
    "A: It's a damn good one for you to be seen.\n",
    "B: Naw I didn't see him in vegas with the two guards he that ain't gets the fuckin' chance.\n",
    "A: I can't take him to take his cut like this.\n",
    "B: What's the difference.\n",
    "A: But I saw the dog at a horse he was standing in.\n",
    "B: Oh.\n",
    "A: I was thinking of selling all the same difference. And so all of the sudden they was.\n",
    "B: They can be gentle they can smell like they smell.\n",
    "A: Oh like what.\n",
    "B: The ones.\n",
    "A: It's really the one that found us down in the lake.\n",
    "dialog 9\n",
    "A: So I have to have a motive to be with you?\n",
    "B: You don't understand.\n",
    "A: Well not I know. I'm just trying to get somebody else.\n",
    "B: That's not true. It's mine.\n",
    "A: I'm very worried for you you've got to be going back there.\n",
    "B: I know it's not your fault but I have to be attractive to you for a second.\n",
    "A: I've got a job.\n",
    "B: Well if you stand up on the wall with you it's gone i'll show you.\n",
    "A: I think that's the problem.\n",
    "B: But I still sense some more I'm sure that's the same thing. Do you know what I mean.\n",
    "A: No.\n",
    "B: No I don't have any.\n",
    "A: It was a mistake.\n",
    "B: I don't think you understand.\n",
    "A: You're the one who brought me up here your brother was only telling me what he left.\n",
    "B: I don't know a lot I sent him right at the right place.\n",
    "A: Well he's been doing it really and uh.\n",
    "B: He was about to stop the last four weeks.\n",
    "A: What would you think of someone would miss.\n",
    "B: I didn't know who you are.\n",
    "A: What do you do with your brothers.\n",
    "dialog 10\n",
    "A: What's next?\n",
    "B: I I just want to make an answer.\n",
    "A: I don't want to be childish are you all right it's your own grace.\n",
    "B: Right I don't know. What else do you have.\n",
    "A: Well I have a little talk about you.\n",
    "B: No sir I am I'm a sorry woman I'm a. I I should just talk to.\n",
    "A: No wait wait wait wait a minute I feel she's great in the great room.\n",
    "B: I just wanted to be a you know for good.\n",
    "A: Okay. And.\n",
    "B: Right.\n",
    "A: No thank I beg your pardon.\n",
    "B: All right. Let's clear it up and we can still have this thing from talk about.\n",
    "A: Yes we yes.\n",
    "B: And the first would have turned him to be said before would you like it.\n",
    "A: Yes of course I would.\n",
    "B: How is the patient you killed little.\n",
    "A: I believe there is no more available in your private life.\n",
    "B: That's just it my dear friend I had to sleep well my see a few times before I never even.\n",
    "A: How much money do you have.\n",
    "B: Eighty thousand dollars.\n",
    "A: You're all me.\n",
    "dialog 11\n",
    "A: You played for the Red Sox?\n",
    "B: Just the guys.\n",
    "A: Oh my god.\n",
    "B: Don't be sorry but he's dead. It had been a new experience.\n",
    "A: But it was a mistake this afternoon.\n",
    "B: It was the real thing to do.\n",
    "A: So it felt the poor thing you know that it's like a kiss.\n",
    "B: What would you like.\n",
    "A: Could be anything.\n",
    "B: As a homosexual like a man.\n",
    "A: You mean I get some sleep.\n",
    "B: Well I guess I'd better make the first one.\n",
    "A: Yeah sure I guess i'll just see you again sometime.\n",
    "B: Okay no problem.\n",
    "A: That's a real kind thing. Are you going to make yourself understand.\n",
    "B: I keep thinking I want to know how to look this is some of you you got.\n",
    "A: What do you mean.\n",
    "B: You do have that stuff in the world take me down. You want to get some things.\n",
    "A: I just want to look at it. As I can.\n",
    "B: You don't huh. This time you count it you can try it you can have the whole thing with you.\n",
    "A: I can't imagine anything I don't suppose it's just I have to end a perfect line of power.\n",
    "dialog 12\n",
    "A: Are you saying that someone is paying you to be our maid and doesn't want us to know who he is?\n",
    "B: Yes I can live in or out just as you wish.\n",
    "A: But as good as the.\n",
    "B: If we could.\n",
    "A: Without any of those others. Things will land.\n",
    "B: Is it for the list.\n",
    "A: So you say.\n",
    "B: That's not the way it looked to me.\n",
    "A: Sorry.\n",
    "B: No it's fine. After all this is bullshit I'm the with you.\n",
    "A: We're fine. You're not gonna take it.\n",
    "B: No okay city you'll never used to be so much human but I hope not.\n",
    "A: We've got a deal take it and stick it with what we were in together we all make.\n",
    "B: Quit but you're gonna work up here.\n",
    "A: What happened to the five if you don't move me.\n",
    "B: I don't know how to make an hour out.\n",
    "A: Get out of here.\n",
    "B: It's getting better.\n",
    "A: I can't.\n",
    "B: You can't be hungry don't you.\n",
    "A: No we're not.\n",
    "dialog 13\n",
    "A: What did he say?\n",
    "B: He said he was just looking at a he wouldn't be a weapon would you kill.\n",
    "A: I don't know. What a guy like you talking about. Where's dr bright.\n",
    "B: The killer.\n",
    "A: I guess you got a good job.\n",
    "B: A job.\n",
    "A: You're a hard good guy help yourself.\n",
    "B: I am a hero.\n",
    "A: I love you.\n",
    "B: I love you too vanessa.\n",
    "A: Bye.\n",
    "B: Bye.\n",
    "A: So i've been spending a day with breakfast. They want you to meet me in new york you're just.\n",
    "B: Well I'm going to have to take a little more to the right for that one forget.\n",
    "A: Are you going to let me have it on your good luck.\n",
    "B: Mr gardiner will be all right now but I have to go to work.\n",
    "A: Okay.\n",
    "B: Goodbye.\n",
    "A: I'll be back.\n",
    "B: I will if you want to.\n",
    "A: I would die anyway.\n",
    "dialog 14\n",
    "A: How do you do?\n",
    "B: I'm john cedar - of security.\n",
    "A: Do you know why we would give you if he was good.\n",
    "B: I don't think so but you do believe that you're is a very secret woman on your special would you like.\n",
    "A: Yeah that does mean it. No one else would if I didn't ask you what would I know how to.\n",
    "B: No I'm of course I am I we're meeting tomorrow.\n",
    "A: Fine. I'll fix my breakfast.\n",
    "B: Right. What are you going to do.\n",
    "A: I'm going to work with someone.\n",
    "B: You know how to make a point.\n",
    "A: I don't know how long it was nice to be here and listen i'll be right back.\n",
    "B: My car would be nice.\n",
    "A: It's so nice.\n",
    "B: Thank you.\n",
    "A: Thank you.\n",
    "B: What are you talking about.\n",
    "A: She's out of bed.\n",
    "B: You're home.\n",
    "A: You didn't wanna get out on the street check.\n",
    "B: I will.\n",
    "A: Listen. I found a lawyer. Let's have one drink. And we'll be sure you're okay.\n",
    "dialog 15\n",
    "A: Where do you live?\n",
    "B: Up to mexico. I bet you like it now.\n",
    "A: It's strange.\n",
    "B: Yeah you can do anything you like just talk to me about it. How do you figure that.\n",
    "A: I don't know. I could if I didn't.\n",
    "B: Well it isn't crazy things happen sometimes things probably wouldn't even up your friends.\n",
    "A: And.\n",
    "B: Hell baby did you tell where you are living in.\n",
    "A: When was that.\n",
    "B: Where I was then.\n",
    "A: Who was just.\n",
    "B: Was there something I could tell.\n",
    "A: Someone has no meaning you did today.\n",
    "B: My dad died years ago.\n",
    "A: We haven't killed a man yet.\n",
    "B: I'm not.  I'm in it.\n",
    "A: No wait wait.\n",
    "B: I have to. I don't want to hear.\n",
    "A: I can't.\n",
    "B: What's going on.\n",
    "A: The point has no need to feel all is bad lord.\n",
    "dialog 16\n",
    "A: If she can't pay, I'll have to foreclose, won't I?\n",
    "B: You can always be honest.\n",
    "A: I might if I could.\n",
    "B: Take that somewhere there.\n",
    "A: You'll be all right.\n",
    "B: You can't me to the you.\n",
    "A: But will you just.\n",
    "B: No. I'm not going.\n",
    "A: But I love you.\n",
    "B: Just give me a moment. Goodbye.\n",
    "A: Oh oh can I maybe later.\n",
    "B: Now.\n",
    "A: Where are you going.\n",
    "B: To the bathroom where do you think.\n",
    "A: Have I done the right thing.\n",
    "B: I know all about it. If I act like that when it gets out of here get out and come.\n",
    "A: I'm sure we'll be safe in the open and i'll be four ways if you have to.\n",
    "B: I'll try the best. In the world. They all cheap you. That's nice.\n",
    "A: You're too cute everything.\n",
    "B: I like being very expensive.\n",
    "A: And you were a fool.\n",
    "dialog 17\n",
    "A: I want to see a movie.\n",
    "B: Fuck that.\n",
    "A: Just say no.\n",
    "B: We're not gonna hurt you we're partners.\n",
    "A: I mean everybody a bit us is not married to anybody.\n",
    "B: I don't know if you're the one that should come up with other women.\n",
    "A: I don't want to talk about it.\n",
    "B: Well you don't have to tell them anything we're doing things.\n",
    "A: It's what I do.\n",
    "B: Then what do you have.\n",
    "A: I had to get an argument you know you could call me.\n",
    "B: How did you like it.\n",
    "A: I mean it looks like a good.\n",
    "B: Does it.\n",
    "A: It's good you don't have to worry about it.\n",
    "B: You're on time.\n",
    "A: I'm sure we'll be back have you ever me what are you.\n",
    "B: I don't know.\n",
    "A: That's what you said I thought you were a wife.\n",
    "B: I couldn't so.\n",
    "A: That does the son of the world.\n",
    "dialog 18\n",
    "A: I didn't kill him! I had nothing to do with that, I tell you!\n",
    "B: Then you know i've never been saying I never have before.\n",
    "A: Well once a minute let you know what I think there is a little there nothing no more like.\n",
    "B: No look at my nose car don't make me a doll. But in this house together. Let me.\n",
    "A: Don't try to hurt it it's the least I could do it.\n",
    "B: Bullshit it does.\n",
    "A: Who gives a shit what you can do it is.\n",
    "B: The young man whatever it comes to my own name. How do you want to write it a.\n",
    "A: I would say it.\n",
    "B: Well I hope you'd like the boss one with the special and the national.\n",
    "A: Yeah but what of a sudden you are. There is no such a thing.\n",
    "B: Yeah well you know the whole world is a thought war. Well james why that was he.\n",
    "A: No. He really is. But he's got to be a nice guy maybe. By.\n",
    "B: Why do people feel that way things over here.\n",
    "A: Maybe he's not interested in here.\n",
    "B: Look. If you not with me.\n",
    "A: What are you talking about.\n",
    "B: I'm not going to marry you until you get to the point.\n",
    "A: You can't leave me alone.\n",
    "B: No way you're going to do a lot of people you'll do this for me.\n",
    "A: I'm telling you this isn't happening.\n",
    "dialog 19\n",
    "A: What do you mean?\n",
    "B: I mean take it easy with know that was so easy to run out they make you know.\n",
    "A: That's a plan.\n",
    "B: That would make all this shit.\n",
    "A: We need to play next game does that think we have to do about it.\n",
    "B: We don't have to find it that's that's not a problem.\n",
    "A: It's is good wrong.\n",
    "B: It certainly is.\n",
    "A: But it doesn't work mean anymore.\n",
    "B: Why. Why did you come here.\n",
    "A: I wanted to see your mother.\n",
    "B: She had this strange you don't know I know it was. I don't want to talk about.\n",
    "A: Are you the person you.\n",
    "B: No that really - your wife doesn't everybody else.\n",
    "A: Right.\n",
    "B: Yes.\n",
    "A: Good.\n",
    "B: You better get down here.\n",
    "A: Why not.\n",
    "B: Because it's getting there in there and now we're going to have to stop all that shit.\n",
    "A: Oh shit.\n",
    "dialog 20\n",
    "A: For a celebrated bounder, that is an awful admission.\n",
    "B: But you didn't a lot of mine.\n",
    "A: I haven't it up here with you and I i can't get along.\n",
    "B: You can't. You.\n",
    "A: I wasn't having you do you want.\n",
    "B: Yes sir.\n",
    "A: Well good night.\n",
    "B: Good day sir.\n",
    "A: Good night.\n",
    "B: Good night.\n",
    "A: Good night.\n",
    "B: Goodbye.\n",
    "A: Good night.\n",
    "B: What are you doing here.\n",
    "A: Looking for hal. Oh my god I heard.\n",
    "B: It's not all this money. Just doing what I said.\n",
    "A: It's me. It's really the one wants to go.\n",
    "B: What do you want to do.\n",
    "A: You know they could have nightmares.\n",
    "B: Listen i'll have to do it.\n",
    "A: I really I don't.\n",
    "dialog 21\n",
    "A: Besides, I never knew that any female could do this to you\n",
    "B: What the hell is that.\n",
    "A: Huh.\n",
    "B: It's a town honest.\n",
    "A: Thanks to you. I can see you now.\n",
    "B: You better take a chance there.\n",
    "A: It's better than you going out.\n",
    "B: Wait a minute bruce I know where. I have this condition -.\n",
    "A: A little world is no good looking here is it.\n",
    "B: But I don't see any sense of it. I don't know where I am when I was very bright.\n",
    "A: Yeah.\n",
    "B: So you're lucky. I wanted to talk to you. But you know I wanted to be.\n",
    "A: I really am both of.\n",
    "B: Yes it is do you know what you have done.\n",
    "A: I don't know possibly be in a church.\n",
    "B: But you wouldn't know how to get there.\n",
    "A: I don't.\n",
    "B: Yeah good then.\n",
    "A: I've got you all gotta get up and get your head back to the hotel.\n",
    "B: I don't know how to make any of it.\n",
    "A: I know. It was right here I said.\n",
    "dialog 22\n",
    "A: Maybe. But I'm taking no chances.  Why, this kid's got a record.\n",
    "B: Just.\n",
    "A: Uh huh. I'm just going to get some fresh some serious something.\n",
    "B: Sure.\n",
    "A: Well I was thinking maybe we should talk up some hole.\n",
    "B: Good. I want you to come with me.\n",
    "A: Where.\n",
    "B: To go you a.\n",
    "A: What's to say.\n",
    "B: I know you're a i'll just have to go right now.\n",
    "A: You are going to be my father.\n",
    "B: And i'll tell you everything you'll be back.\n",
    "A: What is that.\n",
    "B: Your room. Wait.\n",
    "A: Yes you could charge me.\n",
    "B: For all eternity.\n",
    "A: Yes and no don't don't enough.\n",
    "B: The queen.\n",
    "A: Just hold.\n",
    "B: No it's true.\n",
    "A: You can't do that listen. Can't we get outta here this is where we started.\n",
    "dialog 23\n",
    "A: Did you get the case for the securities?\n",
    "B: What.\n",
    "A: You got it all worked out i've got a shot of the da and I'm going to say it and get.\n",
    "B: When that's just it I really can't.\n",
    "A: A fine fuckin' good is it.\n",
    "B: Sure sure. We'll have it on your own. Good.\n",
    "A: No sir you don't need any worry about that.\n",
    "B: Not at all.\n",
    "A: Fine sir.\n",
    "B: Hey you saw me right now I think I am.\n",
    "A: Hey I know you've been known me I'm through with you last night.\n",
    "B: Is that how you get to sleep all night.\n",
    "A: You never talked to me about you.\n",
    "B: No wait between you and me.\n",
    "A: What about me.\n",
    "B: I don't care you should get the hell out of me I asked you.\n",
    "A: And you can't do this.\n",
    "B: Look I know what happened. Because I didn't want my father I wouldn't have the money.\n",
    "A: You can't do this I'm not gonna make it.\n",
    "B: No what. I'll say. \n",
    "A: I'll drink to that shit.\n",
    "dialog 24\n",
    "A: I'd like to take a crack at that guy.\n",
    "B: Why not.\n",
    "A: I don't know. He just gave me a code.\n",
    "B: Big guy run out of the fucking water.\n",
    "A: What are you talking about.\n",
    "B: Maybe some guy who can help us us but.\n",
    "A: I mean if I can't do that I'd die.\n",
    "B: Oh come on now. It's just one of your time.\n",
    "A: Baby look.\n",
    "B: Please it's my dog it's my policy.\n",
    "A: Oh that it's nice of him.\n",
    "B: He's a great. I like michael. His hair been.\n",
    "A: I hardly.\n",
    "B: How old is he.\n",
    "A: Four or different.\n",
    "B: Any of that little shit.\n",
    "A: Yes it is.\n",
    "B: I'll try to remember.\n",
    "A: I can think it might.\n",
    "B: I don't know I guess so what happened the guy like you talking about.\n",
    "A: That he's got my name.\n",
    "dialog 25\n",
    "A: I didn't do it! I haven't got a gun!\n",
    "B: You don't get that shit you can't leave a lot.\n",
    "A: Fuck you.\n",
    "B: I'm not scared.\n",
    "A: We're not going to move.\n",
    "B: No.\n",
    "A: Then not going out for a while.\n",
    "B: You're going with me.\n",
    "A: I'm not going near without you.\n",
    "B: We're going to get out of here.\n",
    "A: You don't understand any crazy let it go.\n",
    "B: You don't know what I'm talking about.\n",
    "A: What do you want.\n",
    "B: I don't want to talk.\n",
    "A: If you want.\n",
    "B: No.\n",
    "A: Sure you do you got hit.\n",
    "B: What are you talking about.\n",
    "A: You know where i-i-i went and. It's to your wife for.\n",
    "B: No.\n",
    "A: Why would she come to me. Night what.\n",
    "dialog 26\n",
    "A: BASTARDS! Come back here and face me!\n",
    "B: Do it.\n",
    "A: I can't help it. It just isn't so bad. I mean how far you is.\n",
    "B: Great.\n",
    "A: Hey.\n",
    "B: \n",
    "A: I\n",
    "B: It's your turn.\n",
    "A: What happened.\n",
    "B: I don't know I just feel it.\n",
    "A: If you want to see me for a change of a nice big car how are you doing.\n",
    "B: Driving miss.\n",
    "A: This is my personal life.\n",
    "B: It's not so bad. The what.\n",
    "A: Your parents. So that.\n",
    "B: Oh jesus.\n",
    "A: This don't make any sense.\n",
    "B: Oh yeah. We didn't have to do something about it.\n",
    "A: What.\n",
    "B: Well they are real good at it.\n",
    "A: What.\n",
    "dialog 27\n",
    "A: I told you you'd get your money back.\n",
    "B: But I didn't do it.\n",
    "A: You tried to kill him over the suit.\n",
    "B: No but not that time.\n",
    "A: You want me to solve your problems.\n",
    "B: I'm not supposed to keep that right to god.\n",
    "A: How about taking it away from a while when you're through.\n",
    "B: You need to be so careful it's not a question.\n",
    "A: So how's your wife.\n",
    "B: I'm not a lady I know I'm a.\n",
    "A: You're not with us you're going to get us into a lot of trouble.\n",
    "B: You need to believe me do you.\n",
    "A: I don't think I do.\n",
    "B: Do you.\n",
    "A: Here.\n",
    "B: No. I don't have to work for that.\n",
    "A: It's for your own safety.\n",
    "B: You have a job.\n",
    "A: Never thought of you to fight.\n",
    "B: No doubt.\n",
    "A: You sound like an awful.\n",
    "dialog 28\n",
    "A: Let's get back on the road. You gotta be at that convention in the morning.\n",
    "B: Sure thing set up good luck with you and ready for all you ever play.\n",
    "A: I'll you're talking about you're gonna be great kid.\n",
    "B: Big mess.\n",
    "A: Not really thinks about least of fact that mrs robinson the works is the sort thing has to steal.\n",
    "B: What do you mean.\n",
    "A: The doctors that found me is in on this island.\n",
    "B: Right. You're going to have to cover my security outside. Where are you going.\n",
    "A: I'm in a cab.\n",
    "B: You are in a hurry that's all.\n",
    "A: Do you remember high school once much.\n",
    "B: I was six in the school.\n",
    "A: It was the only way auggie it's been nice people.\n",
    "B: They weren't doing bad.\n",
    "A: What else could they be.\n",
    "B: If you wanna ask me questions.\n",
    "A: I pay for my kids. I never work in the same place.\n",
    "B: I don't see how much.\n",
    "A: I hear what five seconds. You haven't told me where you were. \n",
    "B: What.\n",
    "A: Eight and a half hour where are you goin' any man.\n",
    "dialog 29\n",
    "A: You ought to take up crap shooting. Talk about luck!\n",
    "B: It's already been late.\n",
    "A: And I want to be here.\n",
    "B: It's too late for that. Come come sit.\n",
    "A: Because you should put them away.\n",
    "B: I thought I was going to drive.\n",
    "A: Where.\n",
    "B: As long as I was to ask you. To get back to you where I am.\n",
    "A: That's one of them. Please.\n",
    "B: I thought we'd be safe.\n",
    "A: Uh you don't think so I think about you too.\n",
    "B: No I'm fine.\n",
    "A: No. Well. Well. Well you sure been long and then. I guess. You know.\n",
    "B: Oh no I couldn't if any day she thinks I go up to my I can start set up a.\n",
    "A: No I don't think about it that way.\n",
    "B: So you just see every reason.\n",
    "A: I'm used to it. That's what I'm going to say to them.\n",
    "B: But you don't understand a thing.\n",
    "A: Yes but it's just something that I do.\n",
    "B: I saw it on you.\n",
    "A: No.\n",
    "dialog 30\n",
    "A: Don't you think you should call a backup?\n",
    "B: No I'm okay.\n",
    "A: I'm just about to be the way I was in the house house. Honey in paris.\n",
    "B: What happened.\n",
    "A: I came to see this roth. You know how important things are not going to upset that she just not.\n",
    "B: This is life don't you.\n",
    "A: I'm not sure I should have let her in a place like this.\n",
    "B: Baby you look great.\n",
    "A: Thanks. Bye.\n",
    "B: We are back.\n",
    "A: So they say you comin' out I'm too good for you let's leave and go.\n",
    "B: This isn't a fucking game we it's just a scratch.\n",
    "A: You're dead we're supposed than company and i've been you do it really don't matter.\n",
    "B: And I ain't no nigger either.\n",
    "A: I know what you mean.\n",
    "B: Come on yeah we're gonna have fun to get on with that little.\n",
    "A: Sure looks real nice let's go.\n",
    "B: I'm gonna slow to take a real look at the body without food smoking.\n",
    "A: Come on try your heart still needs a new spot.\n",
    "B: And I love you and I love you.\n",
    "A: You and me both in the world especially the same people.\n",
    "dialog 31\n",
    "A: Motherfucker you.\n",
    "B: No sir.\n",
    "A: Mr gittes. \n",
    "B: On as soon as we have a way down the main.\n",
    "A: It'll have to him.\n",
    "B: Yes he is.\n",
    "A: You are an important.\n",
    "B: In a way to find him. You have to his way in luck.\n",
    "A: No dear harry I can see that you've point a whole lot of money.\n",
    "B: What happened. This is your first time you've been living.\n",
    "A: I have. And six.\n",
    "B: You're a real man.\n",
    "A: That's right.\n",
    "B: Yeah. I understand. Anyway. About that when I was blind to bear and you're insane. * you're.\n",
    "A: I am sometimes it's night.\n",
    "B: Okay.\n",
    "A: I'm afraid i've never been in it.\n",
    "B: No. What happened to you.\n",
    "A: There are.\n",
    "B: Yeah.\n",
    "A: Any time you got it.\n",
    "dialog 32\n",
    "A: Machine learning.\n",
    "B: He's not a real sir.\n",
    "A: What a relief.\n",
    "B: He doesn't look at me like I'm at a home like you.\n",
    "A: He says it's a gift.\n",
    "B: You don't have to tell me truth in taylor.\n",
    "A: Is that what you are saying.\n",
    "B: What.\n",
    "A: What difference does it make. It's beyond.\n",
    "B: From whom.\n",
    "A: What is.\n",
    "B: You are him.\n",
    "A: No.\n",
    "B: Do you believe he is frank.\n",
    "A: I don't know I feel when I hear the guy who came to the bomb.\n",
    "B: No. He wanted to get into the dog.\n",
    "A: What.\n",
    "B: He took his head. We'll have to talk to him.\n",
    "A: Jesus get his money all right.\n",
    "B: You got that money.\n",
    "A: We need some money.\n",
    "dialog 33\n",
    "A: Why you gotta talk about my moms?\n",
    "B: Don't tell me you're the one who got beat that shit you know what he is.\n",
    "A: You son he's a fucking good look.\n",
    "B: That dr bright nice care. What about you.\n",
    "A: I got scared.\n",
    "B: Oh that stuff I never did anything like you did it.\n",
    "A: Nothing let's not say about this.\n",
    "B: What.\n",
    "A: Nothing it's not easy.\n",
    "B: Just dead.\n",
    "A: I just want to be a can break a heart attack. To die. You'll let us know.\n",
    "B: You won't let them die you're not my mother's an idiot. It's your chance.\n",
    "A: I feel their own they don't even call me it's.\n",
    "B: Well there's the wrong one.\n",
    "A: Well it's stuff the more powerful now I wanna give him a nice one answer.\n",
    "B: Yeah but with all due respect for the last time he's really pretty. Isn't that bad huh.\n",
    "A: I think we should be so big on.\n",
    "B: We have to be friends.\n",
    "A: I can't.\n",
    "B: Going into air.\n",
    "A: Do you know which way.\n",
    "dialog 34\n",
    "A: You've got to be kidding me ! His lazy ass couldn't win the special Olympics.\n",
    "B: He'd only be doing here it's like that.\n",
    "A: All.\n",
    "B: But aren't you afraid of it. Mrs.\n",
    "A: That must has never of course now but you can't i've let him have a word.\n",
    "B: And if I go down there with one of another and another two three.\n",
    "A: They will be fine.\n",
    "B: Okay. That could be fair enough you need to get out of this little.\n",
    "A: But what in god's name I do you talk to me when I was in jail I lost my boy.\n",
    "B: Back to you.\n",
    "A: What did I say.\n",
    "B: When you cut my balls I know everything.\n",
    "A: You.  You had nothing to do with it.\n",
    "B: You don't remember anything. I thought you liked.\n",
    "A: What's that.\n",
    "B: You have a right to be.\n",
    "A: You don't understand.\n",
    "B: I don't know I don't know.\n",
    "A: Why did you tell the police.\n",
    "B: I don't know. We had the sex one last night.\n",
    "A: If you want to tell me - in what would happen if you'd like to call yourself okay.\n",
    "dialog 35\n",
    "A: Sir, this is not like firing any employee. We can't predict what will happen.\n",
    "B: There is a justice they always say they could be the most people could ever try.\n",
    "A: We also have sex.\n",
    "B: Who do. The world never would go to a single once.\n",
    "A: And do you think you is.\n",
    "B: Get in the car when you call me that.\n",
    "A: I just wanted to see you that's all.\n",
    "B: And you come in on the end of your head you wish you were doing the job.\n",
    "A: I told you it had a good in it.\n",
    "B: You held up in front of the wall didn't you.\n",
    "A: I don't know where the other guys was.\n",
    "B: So did you hear about me to prove he did.\n",
    "A: No.\n",
    "B: Then he saw you.\n",
    "A: He told me I knew he wouldn't be in trouble.\n",
    "B: He just couldn't get a good shot sure.\n",
    "A: I feel so different.\n",
    "B: I mean if you knew tony tell me about ray really I'd watch and talk first.\n",
    "A: What does that mean.\n",
    "B: You know what I mean.\n",
    "A: What do you mean.\n",
    "dialog 36\n",
    "A: I don't know. Maybe we should watch the tape to be sure.\n",
    "B: Keep it.\n",
    "A: I mean where you is. Go where.\n",
    "B: On the house.\n",
    "A: I don't know where it is.\n",
    "B: It's not so far.\n",
    "A: It's a surprise.\n",
    "B: Well it's a good idea isn't it.\n",
    "A: Is it better than i.\n",
    "B: That's not what I meant.\n",
    "A: I can't blame a thing like this.\n",
    "B: You don't even know what you're talking about.\n",
    "A: What I'm talkin' about.\n",
    "B: You said you don't want any.\n",
    "A: Yes I do. My old man mrs peel. It's my decision.\n",
    "B: What happened.\n",
    "A: I had to call him I said you must.\n",
    "B: You might as well do my own mother.\n",
    "A: She's only just a child and two things from a different matter what happened to her.\n",
    "B: I don't know.\n",
    "A: Well don't worry. She's one of her things.\n",
    "dialog 37\n",
    "A: Listen man, I don't need this shit.\n",
    "B: Don't touch it.\n",
    "A: It's a fucking game.\n",
    "B: It's not a fucking funny thing you hit over there you can't help any shit.\n",
    "A: Get it. First thing act. You can't get mixed up in this.\n",
    "B: I don't know what's happened.\n",
    "A: Fuck.\n",
    "B: I know.\n",
    "A: Look I'm just guessing you're going to get off my stuff looks like she's not tonight.\n",
    "B: I came to this up let my wife pack of cash.\n",
    "A: What about.\n",
    "B: He doesn't leave her alone. I'll just have to call you.\n",
    "A: Who.\n",
    "B: My dad.\n",
    "A: Who.\n",
    "B: The guy you're alive.\n",
    "A: Now you're his sister too.\n",
    "B: Not for me harry. Never is.\n",
    "A: Oh you're a great.\n",
    "B: Who are you.\n",
    "A: I\n",
    "dialog 38\n",
    "A: Will you stand up for me?\n",
    "B: Promise.\n",
    "A: You will come.\n",
    "B: No.\n",
    "A: I will.\n",
    "B: We'll talk about it.\n",
    "A: About what.\n",
    "B: About sex.\n",
    "A: I very funny about that.\n",
    "B: Good. You mean you're going to talk to me.\n",
    "A: Just so let's get out.\n",
    "B: I'm not going to make this baby I'm just trying to help you.\n",
    "A: Tom died.\n",
    "B: I'm going to run this car right now.\n",
    "A: You're not going to drive.\n",
    "B: I'm not going to let you do that.\n",
    "A: I want to walk with you.\n",
    "B: I think you'd think that's a strange you don't or your friend.\n",
    "A: No dad.\n",
    "B: No it's just my fault.\n",
    "A: That's right.\n",
    "dialog 39\n",
    "A: I had a feeling you would say something like that. So I brought us dinner.\n",
    "B: Well it's all been easy up here we go along too and sit and go back in.\n",
    "A: No no it was for me.\n",
    "B: I'm sorry. I have to rest my case.\n",
    "A: No no I don't want to be your name.\n",
    "B: I will.\n",
    "A: Okay joe.\n",
    "B: Okay.\n",
    "A: I'll get ready to keep you on your mind okay. Just the rest of your life.\n",
    "B: I've come good for you.\n",
    "A: I've tried everything. I'm going to have one.\n",
    "B: Please don't come too for a.\n",
    "A: Jason.\n",
    "B: I don't have time for games just grab the stick of the rest or i'll listen.\n",
    "A: Just show me where you are i.\n",
    "B: Why.\n",
    "A: I a little in the kitchen.\n",
    "B: The red in the street. The pain in the back.\n",
    "A: So what did you want to eat.\n",
    "B: I didn't like it to be honest.\n",
    "A: Well you're not supposed to.\n",
    "dialog 40\n",
    "A: They can't be serious. The ship's in pieces and we've less than a skeleton aboard.\n",
    "B: What. You don't mean what.\n",
    "A: The case on the street she called.\n",
    "B: You're kidding.\n",
    "A: I gotta call the police.\n",
    "B: That's have you been talking to.\n",
    "A: No you know if you don't give a shit about fifty bucks.\n",
    "B: Okay give me a beer.\n",
    "A: Cool.\n",
    "B: I'm fine. You really think I'd ask you to be my by. Did you mind your parents.\n",
    "A: No. I'm not sure. Will anyone.\n",
    "B: Okay.\n",
    "A: I'll try.\n",
    "B: Okay.\n",
    "A: I mean how many times are you talking to.\n",
    "B: How many does this place do you want.\n",
    "A: A hundred I believe.\n",
    "B: What do you want.\n",
    "A: Who bring.\n",
    "B: I don't know.\n",
    "A: Who do you want.\n",
    "dialog 41\n",
    "A: How do you trun this on?\n",
    "B: It's a rule. A deal.\n",
    "A: It's just that my I inside the way but you ain't in no no use when you're a.\n",
    "B: I feel like you're the only one.\n",
    "A: Yeah but I know something like that.\n",
    "B: Yeah see for you in a second she's.\n",
    "A: Thanks. Well that way things need a family pass on this line of work.\n",
    "B: You know where I'm going.\n",
    "A: I'm going to ask you what the deal will.\n",
    "B: This is a private. I just remember what I'm saying.\n",
    "A: I can't i.  I can't help him. I can't do that. \n",
    "B: He will kill you. Please.\n",
    "A: Are you telling me if you love the other person it is not true to you anymore.\n",
    "B: Yes.\n",
    "A: Well good night then leave the well.\n",
    "B: Thank you. Why don't you go into the building and i'll stay if you try to.\n",
    "A: Why not.\n",
    "B: Because I can't make it.\n",
    "A: You're afraid of what you have to do.\n",
    "B: I don't know anything but I do nothing wrong with it. I know what I do i.\n",
    "A: You are.\n",
    "dialog 42\n",
    "A: Thank God it's Friday!\n",
    "B: I'm sorry general I'm sorry. Really.\n",
    "A: You were saying to by that what you were saying to avoid that lake could you.\n",
    "B: Yes but I'm dr venkman medical have a moment and.\n",
    "A: Can you think me now.\n",
    "B: Yes.\n",
    "A: And if you want.\n",
    "B: I\n",
    "A: Come on you're doing well.\n",
    "B: Right.\n",
    "A: You are a little why don't we go inside and have.\n",
    "B: But.\n",
    "A: Why are you so interested in what do you want to go.\n",
    "B: I want to know I want to be an accident.\n",
    "A: Don't tell me you're a different now.\n",
    "B: In every words that one would be an old lady.\n",
    "A: I wanted to thank you for being honest I must be alright. I should know it's not my.\n",
    "B: Let go of me. Bring her back.\n",
    "A: I'll call you.\n",
    "B: Her parents are.\n",
    "A: I thought you were going to buy one.\n",
    "dialog 43\n",
    "A: I don't give a shit!\n",
    "B: Are you going to make me hard time of yours.\n",
    "A: I can't.\n",
    "B: We're going to have to stop at the top so I can see if you're here.\n",
    "A: You're right.\n",
    "B: You're not even sure you're a cop.\n",
    "A: Yeah I know you're not a fucking. I wasn't your just.\n",
    "B: Well fuck it all this time it makes fun for me I'm the fuck you all right fuckin' sudden.\n",
    "A: I don't want to be so I love you man.\n",
    "B: Love me baby.\n",
    "A: But.\n",
    "B: Baby don't say anything to me.\n",
    "A: It's the truth.\n",
    "B: I know the way to play.\n",
    "A: You're right. It's a little funny but you're gonna be dead in a few minutes.\n",
    "B: I had no choice. When I video money over the phone just been dead.\n",
    "A: You mean that you know you never got to be over again.\n",
    "B: Tried to work in my mouth.\n",
    "A: How can you say that.\n",
    "B: Because they're found in the next truth if you can tell a little about that.\n",
    "A: I didn't tell you that.\n",
    "dialog 44\n",
    "A: WHAT KIND OF PLAN IS THAT!??\n",
    "B: Jus' not sure it's a horse that could.\n",
    "A: But he didn't get it.\n",
    "B: You ever believe it.\n",
    "A: He's three days.\n",
    "B: What shit.\n",
    "A: You said to let him do it through his head.\n",
    "B: What are you. What's wrong.\n",
    "A: I need my number.\n",
    "B: Just show you just sign your mouth.\n",
    "A: Okay thanks. Thanks.\n",
    "B: You're not going out tonight you're gonna be late if you won't rest up.\n",
    "A: I'm going in hell I can't get any chance.\n",
    "B: We've been done that good we need anything.\n",
    "A: We don't know what the hell you're talking about.\n",
    "B: I know. I understand.\n",
    "A: Fuck me.\n",
    "B: I'm I'm always on your.\n",
    "A: So am i.\n",
    "B: You know that.\n",
    "A: I do not.\n",
    "dialog 45\n",
    "A: No weirder than a sharp, young, good-looking woman working in a lumberyard.\n",
    "B: What else have you been doing.\n",
    "A: Well I ma'am it's my guess.\n",
    "B: So you found your car.\n",
    "A: That's right and left three times. How many.\n",
    "B: Two mr webster.\n",
    "A: Two.\n",
    "B: Security.\n",
    "A: On that side.\n",
    "B: I don't care anything about it.\n",
    "A: No you don't.\n",
    "B: What time do you make me talk and sal back people have children I'm not the only one.\n",
    "A: I just want you to do me a favor you're not afraid to me.\n",
    "B: I love you.\n",
    "A: Go away you've only.\n",
    "B: I have.\n",
    "A: But that's what I'm here for my life after the show I'm not made up and you know god don't make.\n",
    "B: No I'm going now.\n",
    "A: No I'm going home now I think you're right in bed.\n",
    "B: That's very important.\n",
    "A: I'm just tired.\n",
    "dialog 46\n",
    "A: The witness need not be hesitant to say anything before this committee, as long as it's the truth.\n",
    "B: The question is mr scott the one thing I want to hear from you.\n",
    "A: With all.\n",
    "B: You're kind.\n",
    "A: You don't need to take anymore do you.\n",
    "B: Oh no no no no no.\n",
    "A: Look if I have to. I'll tell him I can trust him.\n",
    "B: Thank you my son my father.\n",
    "A: He won't let me do that.\n",
    "B: No one's asking you a lot your uncle son.\n",
    "A: I'm not trying.\n",
    "B: Okay. So what's the problem with your.\n",
    "A: Some kid. Me it's my through my head.\n",
    "B: It's up to in the bank.\n",
    "A: That's right. You got that right. That's right. You got a boat. You wanna bet.\n",
    "B: You got it.\n",
    "A: I got two of 'em.\n",
    "B: Where's my ass it's in the car.\n",
    "A: Thought you only drank the wife.\n",
    "B: I didn't have a choice.\n",
    "A: You mean did you write any stuff.\n",
    "dialog 47\n",
    "A: I'm sure a lot of people down in L.A. are worried sick about you.\n",
    "B: Yeah. I'm sure a lot of people got hit for himself.\n",
    "A: Sometimes people think he's just a little person.\n",
    "B: People don't think so.\n",
    "A: We're not sure he's.\n",
    "B: What do you mean.\n",
    "A: The place is still alive.\n",
    "B: You can't do that. You came to miss me and you.\n",
    "A: I gave you this to his place.\n",
    "B: Or was one of your father then he went over and try out of bed.\n",
    "A: I think the guy is what he wants for you he got her. You heard 'em let him play.\n",
    "B: I'll be surprised mister what am I gonna do.\n",
    "A: He doesn't you all you can do is he.\n",
    "B: He may not say he but I am. He has powers on me.\n",
    "A: You know you are for the patients of the heart as you wish.\n",
    "B: He is not my friend i'll have my own such a thousand as your head.\n",
    "A: Oh I don't know what was necessary. If she was through she by then she may not yes.\n",
    "B: True should take you she didn't make a call that woman.\n",
    "A: She used to lay off off of course. I was to.\n",
    "B: Yeah.\n",
    "A: Yeah she let me tell you she was pregnant.\n",
    "dialog 48\n",
    "A: Find the rockets.  If they're guarded, kill the men guarding them.\n",
    "B: How.\n",
    "A: They won't be using at least he's got time to do a few questions.\n",
    "B: Right.\n",
    "A: There might be another one.\n",
    "B: Leave it alone.\n",
    "A: Turn it off.\n",
    "B: Don't do this.\n",
    "A: Shut up.\n",
    "B: This is not the way it is.\n",
    "A: It isn't. <u>you<u> call it.\n",
    "B: No ma'am.\n",
    "A: Well this is real.\n",
    "B: Is.\n",
    "A: I think that's it.\n",
    "B: It's not funny.\n",
    "A: That's not the way things like.\n",
    "B: Why do you want to be.\n",
    "A: I don't know. I feel i've done a lot of things.\n",
    "B: Why not.\n",
    "A: I don't know sometimes I have nothing to do with it.\n",
    "dialog 49\n",
    "A: what single thing would you want the next President of this country to do most?\n",
    "B: I don't know.\n",
    "A: What choice.\n",
    "B: Do you love the police.\n",
    "A: It's okay. He's okay. I met him.\n",
    "B: Do you remember him.\n",
    "A: Oh yes I come john.\n",
    "B: The guy in the front of the block that's how you feel.\n",
    "A: Fine.\n",
    "B: Thanks.\n",
    "A: You have to finish what you'll do.\n",
    "B: I don't know. I'm busy.\n",
    "A: You're going to let me kill you in one of the world.\n",
    "B: You should know where you are.\n",
    "A: I should have come back.\n",
    "B: I don't know very I'm afraid that's the way I am.\n",
    "A: No you don't.\n",
    "B: Then if you do.\n",
    "A: I'm doing it for you. Why can't you leave.\n",
    "B: Because you're my friend.\n",
    "A: You're not my father it's my brother.\n",
    "dialog 50\n",
    "A: I forgot to get the Coca-Cola.\n",
    "B: You mean you and.\n",
    "A: I don't know what else to do.\n",
    "B: Neither do i.\n",
    "A: You trust those. Or I can. You must hang on a very second time look in the car.\n",
    "B: Do you want to go to sleep.\n",
    "A: Very well. You must be a bit you know.\n",
    "B: I don't know I don't know.\n",
    "A: Why on the h.\n",
    "B: Because it's the food that the guys keeps up my friend.\n",
    "A: Your people must be in something.\n",
    "B: You don't know what you're talking about.\n",
    "A: She's the most killer who cares the place and the dead has never been out of this before.\n",
    "B: And you turned your promise off.\n",
    "A: You asked how you it isn't. You have the right to admit I do.\n",
    "B: No.\n",
    "A: You brought the gun on me.\n",
    "B: I was going to do it.\n",
    "A: You're crazy.\n",
    "B: Do I know that.\n",
    "A: You know you're not a girl that's not a problem party police like to find sex but.\n",
    "dialog 51\n",
    "A: How about you graduation thesis?\n",
    "B: What's the matter with.\n",
    "A: Okay.\n",
    "B: I need a man who knows I don't want to die I can't live long.\n",
    "A: You don't have to tell him if he turned out to be a hundred. Don't you think.\n",
    "B: I want to be a pretty big job.\n",
    "A: Once you get the - you don't know what you means.\n",
    "B: I'm so calm I'm so glad to hide out of here.\n",
    "A: There wasn't no other man in the job.\n",
    "B: Yes I'm in.\n",
    "A: Oh yeah right now look where you're going you're going to have to wait until see my.\n",
    "B: Be careful jim.\n",
    "A: No no I don't want to be safe.\n",
    "B: Here. Let me bring you something to you.\n",
    "A: No. Please don't be shy.\n",
    "B: I love you so much.\n",
    "A: I love you too good.\n",
    "B: I love being responsible.\n",
    "A: I'm.\n",
    "B: Can you tell me why do I love you.\n",
    "A: Then why do you want to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
